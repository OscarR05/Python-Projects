{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete guide to Machine Learning with H2O (AutoML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use the subset of the loan-level dataset from Fannie Mae and Freddie Mac. Firstly, we will solve a binary classification problem (predicting if a loan is delinquent or not). Then, we will explore a regression use-case (predicting interest rates on the same dataset). We will try to do both use-cases using Automatic Machine Learning (AutoML), and we will do so using the H2O-3 Python module in a Jupyter Notebook and also in Flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use H2O AutoML to make below predictions:\n",
    "\n",
    "- Predict whether a mortgage loan will be delinquent or not\n",
    "- Predict the interest rate for each loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Concepts\n",
    "\n",
    "### AutoML\n",
    "Choosing the best machine learning models and tuning them can be time consuming and exhaustive. Often, it requires levels of expertise to know what parameters to tune. The field of AutoML focuses on solving this issue. AutoML is useful both for experts, by automating the process of choosing and tuning a model; and for non-experts as well, by helping them to create high performing models in a short time frame. Some of the aspects of machine learning that can be automated include data preparation, which can include imputation, one-hot encoding, feature selection/extraction, and also feature engineering. Another aspect that can be automated is the model generation, which includes training a model and tuning it with cartesian or random grid search. Lastly, a third aspect that could be using ensembles, as they usually outperform individual models.\n",
    "\n",
    "H2O AutoML is an automated algorithm for automating the machine learning workflow, which includes some light data preparation such as imputing missing data, standardization of numeric features, and one-hot encoding categorical features. It also provides automatic training, hyper-parameter optimization, model search, and selection under time, space, and resource constraints. H2O's AutoML further optimizes model performance by stacking an ensemble of models. H2O AutoML trains one stacked ensemble based on all previously trained models and another one on the best model of each family.\n",
    "\n",
    "The current version of AutoML trains and cross-validates the following model: GLMs, a Random Forest, an Extremely-Randomized Forest, a random grid of Gradient Boosting Machines (GBMs), XGBoosts, a random grid of Deep Neural Nets, and a Stacked Ensemble of all the models. If you would like to know more details about the models trained by AutoML, please visit Which models are trained in the AutoML process? under the FAQ of the AutoML Documentation section.\n",
    "To see how H2O AutoML performs compared to other AutoML algorithms, please look at An Open Source AutoML Benchmark\n",
    "\n",
    "### Stacked Ensembles\n",
    "Ensemble machine learning methods use multiple learning algorithms to obtain better predictive performance than the ones that could be obtained from any of the constituent learning algorithms. Many of the popular modern machine learning algorithms are actually ensembles. For example, Random Forest and Gradient Boosting Machine (GBM) are both ensemble learners. Both bagging (e.g., Random Forest) and boosting (e.g., GBM) are methods for ensembling that take a collection of weak learners (e.g., decision tree) and form a single, strong learner.\n",
    "\n",
    "H2O's Stacked Ensemble method is a supervised ensemble machine learning algorithm that finds the optimal combination of a collection of prediction algorithms using a process called stacking. Like all supervised models in H2O, Stacked Ensemble supports regression, binary classification, and multiclass classification. If you would like to know more, make sure to check the Stacked Ensemble Section in the H2O-3 Documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h2o\n",
    "\n",
    "startup  = '/home/h2o/bin/aquarium_startup'\n",
    "shutdown = '/home/h2o/bin/aquarium_stop'\n",
    "\n",
    "if os.path.exists(startup):\n",
    "    os.system(startup)\n",
    "    local_url = 'http://localhost:54321/h2o'\n",
    "    aquarium = True\n",
    "else:\n",
    "    local_url = 'http://localhost:54321'\n",
    "    aquarium = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.251-b08, mixed mode)\n",
      "  Starting server from c:\\users\\bokhy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\bokhy\\AppData\\Local\\Temp\\tmp9syxelmf\n",
      "  JVM stdout: C:\\Users\\bokhy\\AppData\\Local\\Temp\\tmp9syxelmf\\h2o_bokhy_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\bokhy\\AppData\\Local\\Temp\\tmp9syxelmf\\h2o_bokhy_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.30.1.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 day </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_bokhy_ughxpn</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.524 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O_API_Extensions:</td>\n",
       "<td>Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.7.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       America/Los_Angeles\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.30.1.1\n",
       "H2O_cluster_version_age:    1 day\n",
       "H2O_cluster_name:           H2O_from_python_bokhy_ughxpn\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.524 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         accepting new members, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "H2O_API_Extensions:         Amazon S3, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python_version:             3.7.6 final\n",
       "--------------------------  ---------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(url=local_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Let's import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "loan_level = h2o.import_file(\"https://s3.amazonaws.com/data.h2o.ai/H2O-3-Tutorials/loan_level_50k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  CREDIT_SCORE</th><th style=\"text-align: right;\">  FIRST_PAYMENT_DATE</th><th>FIRST_TIME_HOMEBUYER_FLAG  </th><th style=\"text-align: right;\">  MATURITY_DATE</th><th style=\"text-align: right;\">  METROPOLITAN_STATISTICAL_AREA</th><th style=\"text-align: right;\">  MORTGAGE_INSURANCE_PERCENTAGE</th><th style=\"text-align: right;\">  NUMBER_OF_UNITS</th><th>OCCUPANCY_STATUS  </th><th style=\"text-align: right;\">  ORIGINAL_COMBINED_LOAN_TO_VALUE</th><th style=\"text-align: right;\">  ORIGINAL_DEBT_TO_INCOME_RATIO</th><th style=\"text-align: right;\">  ORIGINAL_UPB</th><th style=\"text-align: right;\">  ORIGINAL_LOAN_TO_VALUE</th><th style=\"text-align: right;\">  ORIGINAL_INTEREST_RATE</th><th>CHANNEL  </th><th>PREPAYMENT_PENALTY_MORTGAGE_FLAG  </th><th>PRODUCT_TYPE  </th><th>PROPERTY_STATE  </th><th>PROPERTY_TYPE  </th><th style=\"text-align: right;\">  POSTAL_CODE</th><th>LOAN_SEQUENCE_NUMBER  </th><th>LOAN_PURPOSE  </th><th style=\"text-align: right;\">  ORIGINAL_LOAN_TERM</th><th style=\"text-align: right;\">  NUMBER_OF_BORROWERS</th><th>SELLER_NAME         </th><th>SERVICER_NAME       </th><th>PREPAID  </th><th>DELINQUENT  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">           707</td><td style=\"text-align: right;\">              200211</td><td>N                          </td><td style=\"text-align: right;\">         202903</td><td style=\"text-align: right;\">                          33340</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               60</td><td style=\"text-align: right;\">                             57</td><td style=\"text-align: right;\">        136000</td><td style=\"text-align: right;\">                      60</td><td style=\"text-align: right;\">                   6.25 </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WI              </td><td>SF             </td><td style=\"text-align: right;\">        53000</td><td>F199Q1000018          </td><td>C             </td><td style=\"text-align: right;\">                 317</td><td style=\"text-align: right;\">                    2</td><td>Other sellers       </td><td>Other servicers     </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           691</td><td style=\"text-align: right;\">              200302</td><td>N                          </td><td style=\"text-align: right;\">         202901</td><td style=\"text-align: right;\">                          15940</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               65</td><td style=\"text-align: right;\">                             25</td><td style=\"text-align: right;\">        130000</td><td style=\"text-align: right;\">                      65</td><td style=\"text-align: right;\">                   5.875</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td style=\"text-align: right;\">        44700</td><td>F199Q1000023          </td><td>P             </td><td style=\"text-align: right;\">                 312</td><td style=\"text-align: right;\">                    2</td><td>Other sellers       </td><td>Other servicers     </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           730</td><td style=\"text-align: right;\">              199903</td><td>N                          </td><td style=\"text-align: right;\">         202902</td><td style=\"text-align: right;\">                          16620</td><td style=\"text-align: right;\">                             30</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               94</td><td style=\"text-align: right;\">                             29</td><td style=\"text-align: right;\">        138000</td><td style=\"text-align: right;\">                      94</td><td style=\"text-align: right;\">                   7    </td><td>T        </td><td>N                                 </td><td>FRM           </td><td>WV              </td><td>SF             </td><td style=\"text-align: right;\">        25300</td><td>F199Q1000037          </td><td>P             </td><td style=\"text-align: right;\">                 360</td><td style=\"text-align: right;\">                    2</td><td>Other sellers       </td><td>Other servicers     </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           638</td><td style=\"text-align: right;\">              199905</td><td>N                          </td><td style=\"text-align: right;\">         202904</td><td style=\"text-align: right;\">                          42020</td><td style=\"text-align: right;\">                            nan</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               67</td><td style=\"text-align: right;\">                             28</td><td style=\"text-align: right;\">        160000</td><td style=\"text-align: right;\">                      67</td><td style=\"text-align: right;\">                   7.375</td><td>T        </td><td>N                                 </td><td>FRM           </td><td>CA              </td><td>SF             </td><td style=\"text-align: right;\">        93400</td><td>F199Q1000067          </td><td>N             </td><td style=\"text-align: right;\">                 360</td><td style=\"text-align: right;\">                    2</td><td>CROSSLAND MORTGAGE C</td><td>CHASEMTGECO         </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           577</td><td style=\"text-align: right;\">              199903</td><td>N                          </td><td style=\"text-align: right;\">         202902</td><td style=\"text-align: right;\">                          12580</td><td style=\"text-align: right;\">                             12</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               80</td><td style=\"text-align: right;\">                             53</td><td style=\"text-align: right;\">         43000</td><td style=\"text-align: right;\">                      80</td><td style=\"text-align: right;\">                   7.25 </td><td>T        </td><td>N                                 </td><td>FRM           </td><td>MD              </td><td>SF             </td><td style=\"text-align: right;\">        21200</td><td>F199Q1000086          </td><td>N             </td><td style=\"text-align: right;\">                 360</td><td style=\"text-align: right;\">                    1</td><td>ACCUBANC MORTGAGE CO</td><td>GMACMTGECORP        </td><td>FALSE    </td><td>TRUE        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           693</td><td style=\"text-align: right;\">              199905</td><td>N                          </td><td style=\"text-align: right;\">         202904</td><td style=\"text-align: right;\">                            nan</td><td style=\"text-align: right;\">                            nan</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               80</td><td style=\"text-align: right;\">                             43</td><td style=\"text-align: right;\">         93000</td><td style=\"text-align: right;\">                      80</td><td style=\"text-align: right;\">                   7.125</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>SD              </td><td>SF             </td><td style=\"text-align: right;\">        57500</td><td>F199Q1000104          </td><td>P             </td><td style=\"text-align: right;\">                 360</td><td style=\"text-align: right;\">                    1</td><td>NORWEST MORTGAGE, IN</td><td>WELLSFARGOHOMEMORTGA</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           739</td><td style=\"text-align: right;\">              199905</td><td>                           </td><td style=\"text-align: right;\">         202904</td><td style=\"text-align: right;\">                          16700</td><td style=\"text-align: right;\">                            nan</td><td style=\"text-align: right;\">                1</td><td>S                 </td><td style=\"text-align: right;\">                               80</td><td style=\"text-align: right;\">                             25</td><td style=\"text-align: right;\">        200000</td><td style=\"text-align: right;\">                      80</td><td style=\"text-align: right;\">                   6.875</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>SC              </td><td>CO             </td><td style=\"text-align: right;\">        29400</td><td>F199Q1000107          </td><td>P             </td><td style=\"text-align: right;\">                 360</td><td style=\"text-align: right;\">                    2</td><td>NORWEST MORTGAGE, IN</td><td>WELLSFARGOHOMEMORTGA</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           695</td><td style=\"text-align: right;\">              199905</td><td>                           </td><td style=\"text-align: right;\">         202904</td><td style=\"text-align: right;\">                          42044</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               40</td><td style=\"text-align: right;\">                              6</td><td style=\"text-align: right;\">        135000</td><td style=\"text-align: right;\">                      40</td><td style=\"text-align: right;\">                   6.875</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>CA              </td><td>SF             </td><td style=\"text-align: right;\">        92800</td><td>F199Q1000121          </td><td>C             </td><td style=\"text-align: right;\">                 360</td><td style=\"text-align: right;\">                    2</td><td>NATIONSBANC MORTGAGE</td><td>BAMORTGAGE,LLC      </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           753</td><td style=\"text-align: right;\">              199905</td><td>N                          </td><td style=\"text-align: right;\">         202904</td><td style=\"text-align: right;\">                          41740</td><td style=\"text-align: right;\">                              0</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               80</td><td style=\"text-align: right;\">                             17</td><td style=\"text-align: right;\">         59000</td><td style=\"text-align: right;\">                      80</td><td style=\"text-align: right;\">                   7    </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>CA              </td><td>CO             </td><td style=\"text-align: right;\">        92000</td><td>F199Q1000122          </td><td>P             </td><td style=\"text-align: right;\">                 360</td><td style=\"text-align: right;\">                    1</td><td>NATIONSBANC MORTGAGE</td><td>BAMORTGAGE,LLC      </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td style=\"text-align: right;\">           712</td><td style=\"text-align: right;\">              199905</td><td>                           </td><td style=\"text-align: right;\">         202904</td><td style=\"text-align: right;\">                            nan</td><td style=\"text-align: right;\">                            nan</td><td style=\"text-align: right;\">                1</td><td>O                 </td><td style=\"text-align: right;\">                               80</td><td style=\"text-align: right;\">                             28</td><td style=\"text-align: right;\">        126000</td><td style=\"text-align: right;\">                      80</td><td style=\"text-align: right;\">                   7.125</td><td>R        </td><td>N                                 </td><td>FRM           </td><td>MI              </td><td>SF             </td><td style=\"text-align: right;\">        48800</td><td>F199Q1000123          </td><td>N             </td><td style=\"text-align: right;\">                 360</td><td style=\"text-align: right;\">                    2</td><td>Other sellers       </td><td>Other servicers     </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_level.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:49930\n",
      "Cols:27\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>CREDIT_SCORE     </th><th>FIRST_PAYMENT_DATE  </th><th>FIRST_TIME_HOMEBUYER_FLAG  </th><th>MATURITY_DATE     </th><th>METROPOLITAN_STATISTICAL_AREA  </th><th>MORTGAGE_INSURANCE_PERCENTAGE  </th><th>NUMBER_OF_UNITS   </th><th>OCCUPANCY_STATUS  </th><th>ORIGINAL_COMBINED_LOAN_TO_VALUE  </th><th>ORIGINAL_DEBT_TO_INCOME_RATIO  </th><th>ORIGINAL_UPB      </th><th>ORIGINAL_LOAN_TO_VALUE  </th><th>ORIGINAL_INTEREST_RATE  </th><th>CHANNEL  </th><th>PREPAYMENT_PENALTY_MORTGAGE_FLAG  </th><th>PRODUCT_TYPE  </th><th>PROPERTY_STATE  </th><th>PROPERTY_TYPE  </th><th>POSTAL_CODE       </th><th>LOAN_SEQUENCE_NUMBER  </th><th>LOAN_PURPOSE  </th><th>ORIGINAL_LOAN_TERM  </th><th>NUMBER_OF_BORROWERS  </th><th>SELLER_NAME         </th><th>SERVICER_NAME       </th><th>PREPAID  </th><th>DELINQUENT  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int              </td><td>int                 </td><td>enum                       </td><td>int               </td><td>int                            </td><td>int                            </td><td>int               </td><td>enum              </td><td>int                              </td><td>int                            </td><td>int               </td><td>int                     </td><td>real                    </td><td>enum     </td><td>enum                              </td><td>enum          </td><td>enum            </td><td>enum           </td><td>int               </td><td>string                </td><td>enum          </td><td>int                 </td><td>int                  </td><td>enum                </td><td>enum                </td><td>enum     </td><td>enum        </td></tr>\n",
       "<tr><td>mins   </td><td>300.0            </td><td>199902.0            </td><td>                           </td><td>202404.0          </td><td>10180.0                        </td><td>0.0                            </td><td>1.0               </td><td>                  </td><td>6.0                              </td><td>1.0                            </td><td>10000.0           </td><td>6.0                     </td><td>5.0                     </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>600.0             </td><td>NaN                   </td><td>              </td><td>301.0               </td><td>1.0                  </td><td>                    </td><td>                    </td><td>         </td><td>            </td></tr>\n",
       "<tr><td>mean   </td><td>712.306600068478 </td><td>200025.6742239135   </td><td>                           </td><td>203023.3970759063 </td><td>30705.25866529918              </td><td>7.719609503855925              </td><td>1.0281994792709794</td><td>                  </td><td>76.08864765261977                </td><td>32.83933763635988              </td><td>136369.67754856797</td><td>75.74523823829837       </td><td>7.185977708792309       </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>55401.43412250129 </td><td>NaN                   </td><td>              </td><td>359.8508311636291   </td><td>1.629450778447913    </td><td>                    </td><td>                    </td><td>         </td><td>            </td></tr>\n",
       "<tr><td>maxs   </td><td>830.0            </td><td>200403.0            </td><td>                           </td><td>203312.0          </td><td>49740.0                        </td><td>50.0                           </td><td>4.0               </td><td>                  </td><td>160.0                            </td><td>65.0                           </td><td>529000.0          </td><td>100.0                   </td><td>10.625                  </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>99900.0           </td><td>NaN                   </td><td>              </td><td>361.0               </td><td>2.0                  </td><td>                    </td><td>                    </td><td>         </td><td>            </td></tr>\n",
       "<tr><td>sigma  </td><td>54.97355321804359</td><td>109.77460105156621  </td><td>                           </td><td>110.47953133306562</td><td>11363.124822676407             </td><td>12.042273590466618             </td><td>0.219623303648194 </td><td>                  </td><td>15.06208012347409                </td><td>11.165383364972824             </td><td>60632.743281235904</td><td>14.86722833135055       </td><td>0.5835949914330256      </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>29512.322859225387</td><td>NaN                   </td><td>              </td><td>1.9974697613404848  </td><td>0.48295669536262237  </td><td>                    </td><td>                    </td><td>         </td><td>            </td></tr>\n",
       "<tr><td>zeros  </td><td>0                </td><td>0                   </td><td>                           </td><td>0                 </td><td>0                              </td><td>31023                          </td><td>0                 </td><td>                  </td><td>0                                </td><td>0                              </td><td>0                 </td><td>0                       </td><td>0                       </td><td>         </td><td>                                  </td><td>              </td><td>                </td><td>               </td><td>0                 </td><td>0                     </td><td>              </td><td>0                   </td><td>0                    </td><td>                    </td><td>                    </td><td>         </td><td>            </td></tr>\n",
       "<tr><td>missing</td><td>279              </td><td>0                   </td><td>13067                      </td><td>0                 </td><td>7029                           </td><td>5064                           </td><td>0                 </td><td>0                 </td><td>2                                </td><td>1437                           </td><td>0                 </td><td>1                       </td><td>0                       </td><td>0        </td><td>504                               </td><td>0             </td><td>0               </td><td>13             </td><td>4                 </td><td>0                     </td><td>0             </td><td>0                   </td><td>23                   </td><td>0                   </td><td>0                   </td><td>0        </td><td>0           </td></tr>\n",
       "<tr><td>0      </td><td>707.0            </td><td>200211.0            </td><td>N                          </td><td>202903.0          </td><td>33340.0                        </td><td>0.0                            </td><td>1.0               </td><td>O                 </td><td>60.0                             </td><td>57.0                           </td><td>136000.0          </td><td>60.0                    </td><td>6.25                    </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>WI              </td><td>SF             </td><td>53000.0           </td><td>F199Q1000018          </td><td>C             </td><td>317.0               </td><td>2.0                  </td><td>Other sellers       </td><td>Other servicers     </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>1      </td><td>691.0            </td><td>200302.0            </td><td>N                          </td><td>202901.0          </td><td>15940.0                        </td><td>0.0                            </td><td>1.0               </td><td>O                 </td><td>65.0                             </td><td>25.0                           </td><td>130000.0          </td><td>65.0                    </td><td>5.875                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>OH              </td><td>SF             </td><td>44700.0           </td><td>F199Q1000023          </td><td>P             </td><td>312.0               </td><td>2.0                  </td><td>Other sellers       </td><td>Other servicers     </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>2      </td><td>730.0            </td><td>199903.0            </td><td>N                          </td><td>202902.0          </td><td>16620.0                        </td><td>30.0                           </td><td>1.0               </td><td>O                 </td><td>94.0                             </td><td>29.0                           </td><td>138000.0          </td><td>94.0                    </td><td>7.0                     </td><td>T        </td><td>N                                 </td><td>FRM           </td><td>WV              </td><td>SF             </td><td>25300.0           </td><td>F199Q1000037          </td><td>P             </td><td>360.0               </td><td>2.0                  </td><td>Other sellers       </td><td>Other servicers     </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>3      </td><td>638.0            </td><td>199905.0            </td><td>N                          </td><td>202904.0          </td><td>42020.0                        </td><td>nan                            </td><td>1.0               </td><td>O                 </td><td>67.0                             </td><td>28.0                           </td><td>160000.0          </td><td>67.0                    </td><td>7.375                   </td><td>T        </td><td>N                                 </td><td>FRM           </td><td>CA              </td><td>SF             </td><td>93400.0           </td><td>F199Q1000067          </td><td>N             </td><td>360.0               </td><td>2.0                  </td><td>CROSSLAND MORTGAGE C</td><td>CHASEMTGECO         </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>4      </td><td>577.0            </td><td>199903.0            </td><td>N                          </td><td>202902.0          </td><td>12580.0                        </td><td>12.0                           </td><td>1.0               </td><td>O                 </td><td>80.0                             </td><td>53.0                           </td><td>43000.0           </td><td>80.0                    </td><td>7.25                    </td><td>T        </td><td>N                                 </td><td>FRM           </td><td>MD              </td><td>SF             </td><td>21200.0           </td><td>F199Q1000086          </td><td>N             </td><td>360.0               </td><td>1.0                  </td><td>ACCUBANC MORTGAGE CO</td><td>GMACMTGECORP        </td><td>FALSE    </td><td>TRUE        </td></tr>\n",
       "<tr><td>5      </td><td>693.0            </td><td>199905.0            </td><td>N                          </td><td>202904.0          </td><td>nan                            </td><td>nan                            </td><td>1.0               </td><td>O                 </td><td>80.0                             </td><td>43.0                           </td><td>93000.0           </td><td>80.0                    </td><td>7.125                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>SD              </td><td>SF             </td><td>57500.0           </td><td>F199Q1000104          </td><td>P             </td><td>360.0               </td><td>1.0                  </td><td>NORWEST MORTGAGE, IN</td><td>WELLSFARGOHOMEMORTGA</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>6      </td><td>739.0            </td><td>199905.0            </td><td>                           </td><td>202904.0          </td><td>16700.0                        </td><td>nan                            </td><td>1.0               </td><td>S                 </td><td>80.0                             </td><td>25.0                           </td><td>200000.0          </td><td>80.0                    </td><td>6.875                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>SC              </td><td>CO             </td><td>29400.0           </td><td>F199Q1000107          </td><td>P             </td><td>360.0               </td><td>2.0                  </td><td>NORWEST MORTGAGE, IN</td><td>WELLSFARGOHOMEMORTGA</td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>7      </td><td>695.0            </td><td>199905.0            </td><td>                           </td><td>202904.0          </td><td>42044.0                        </td><td>0.0                            </td><td>1.0               </td><td>O                 </td><td>40.0                             </td><td>6.0                            </td><td>135000.0          </td><td>40.0                    </td><td>6.875                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>CA              </td><td>SF             </td><td>92800.0           </td><td>F199Q1000121          </td><td>C             </td><td>360.0               </td><td>2.0                  </td><td>NATIONSBANC MORTGAGE</td><td>BAMORTGAGE,LLC      </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>8      </td><td>753.0            </td><td>199905.0            </td><td>N                          </td><td>202904.0          </td><td>41740.0                        </td><td>0.0                            </td><td>1.0               </td><td>O                 </td><td>80.0                             </td><td>17.0                           </td><td>59000.0           </td><td>80.0                    </td><td>7.0                     </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>CA              </td><td>CO             </td><td>92000.0           </td><td>F199Q1000122          </td><td>P             </td><td>360.0               </td><td>1.0                  </td><td>NATIONSBANC MORTGAGE</td><td>BAMORTGAGE,LLC      </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "<tr><td>9      </td><td>712.0            </td><td>199905.0            </td><td>                           </td><td>202904.0          </td><td>nan                            </td><td>nan                            </td><td>1.0               </td><td>O                 </td><td>80.0                             </td><td>28.0                           </td><td>126000.0          </td><td>80.0                    </td><td>7.125                   </td><td>R        </td><td>N                                 </td><td>FRM           </td><td>MI              </td><td>SF             </td><td>48800.0           </td><td>F199Q1000123          </td><td>N             </td><td>360.0               </td><td>2.0                  </td><td>Other sellers       </td><td>Other servicers     </td><td>TRUE     </td><td>FALSE       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loan_level.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the **DELINQUENT**, which is the response of our classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>DELINQUENT  </th><th style=\"text-align: right;\">  Count</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FALSE       </td><td style=\"text-align: right;\">  48118</td></tr>\n",
       "<tr><td>TRUE        </td><td style=\"text-align: right;\">   1812</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_level[\"DELINQUENT\"].table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the classification tutorial, the dataset is highly imbalanced, which is the same scenario in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loan_level[\"ORIGINAL_INTEREST_RATE\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see that the average interest rate ranges from 7% to 8%, similar to what we saw in the previous tutorial.\n",
    "\n",
    "Now that we have an idea of the distribution of the responses let's split the dataset. For this tutorial, we will take a slightly different approach. Instead of splitting the dataset into three sets, we are just going to do 2, a train and test set. We will be using cross-validation to validate our models, as we need to use the k-fold cross-validation in order to get the stacked ensembles from the AutoML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = loan_level.split_frame([0.8], seed=623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:39988 test:9942\n"
     ]
    }
   ],
   "source": [
    "print(\"train:%d test:%d\" % (train.nrows, test.nrows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. H2O AutoML Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have our train and test sets, so we just need to choose our response variable, as well as the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"DELINQUENT\"\n",
    "ignore = [\"DELINQUENT\", \"PREPAID\", \"PREPAYMENT_PENALTY_MORTGAGE_FLAG\", \"PRODUCT_TYPE\"] \n",
    "x = list(set(train.names) - set(ignore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2o.automl.autoh2o.H2OAutoML at 0x12b0ab05e88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H2OAutoML(nfolds=5, max_runtime_secs=3600, max_models=None, stopping_metric='AUTO', stopping_tolerance=None, stopping_rounds=3, seed=None, project_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, H2O AutoML is designed to have as few parameters as possible, which makes it very easy to use. For this experiment, we could've just changed the maximum runtime, the seed, and the project name; however, from our first tutorial, we learned that our dataset is highly imbalanced and that models have a hard time classifying the minority class. For that reason, we are setting balance_classes=True, and we are setting the sampling factors to [0.5,1.25], which means that we will undersample the majority class, and oversample the minority class. Also, we will set max_models = 25 and to make sure that AutoML trains all 25 models in less than 20 min, we will also set max_runtime_secs_per_model=30 which will make sure no model takes more than 30 seconds to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run AutoML with tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "13:55:38.974: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "████████████████████████████████████████████████████████| 100%\n",
      "Wall time: 10min 52s\n"
     ]
    }
   ],
   "source": [
    "aml = H2OAutoML(max_models=25, max_runtime_secs_per_model=30, seed=623, project_name='classification', \n",
    "                balance_classes=True, class_sampling_factors=[0.5,1.25])\n",
    "%time aml.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only required parameters for H2O's AutoML are, y, training_frame, and max_runtime_secs, which let us train AutoML for ‘x' amount of seconds and/or max_models, which would train a maximum number of models. Please note that max_runtime_secs has a default value, while max_models does not. For this task, we will set a number of models constraint. The seed is the usual parameter that we set for reproducibility purposes. We also need a project name because we will do both classification and regression with AutoML. Lastly, we are setting balance_classes=True because we have a very imbalanced dataset, and we are using the default number of folds for cross-validation.\n",
    "\n",
    "The second line of code has the parameters that we need in order to train our model. For now, we will just pass x, y, and the training frame. Please note that the parameter x is optional because if you were using all the columns in your dataset, you would not need to declare this parameter. The leaderboard frame can be used to score and rank models on the leaderboard, but we will use the validation scores to do so because we will check the performance of our models with the test set.\n",
    "\n",
    "Below is a list of optional parameters that the user could set for H2O's AutoML\n",
    "\n",
    "validation_frame\n",
    "leaderboard_frame\n",
    "blending_frame\n",
    "fold_column\n",
    "weights_column\n",
    "ignored_columns\n",
    "class_sampling_factors\n",
    "max_after_balance_size\n",
    "max_runtime_secs_per_model\n",
    "sort_metric\n",
    "exclude_algos\n",
    "include_algos\n",
    "keep_cross_validation_predictions\n",
    "keep_cross_validation_models\n",
    "keep_cross_validation_fold_assignment\n",
    "verbosity\n",
    "export_checkpoints_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20200812_135538   </td><td style=\"text-align: right;\">0.85201 </td><td style=\"text-align: right;\"> 0.128657</td><td style=\"text-align: right;\">0.215807</td><td style=\"text-align: right;\">              0.331493</td><td style=\"text-align: right;\">0.178643</td><td style=\"text-align: right;\">0.0319133</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20200812_135538</td><td style=\"text-align: right;\">0.849861</td><td style=\"text-align: right;\"> 0.128865</td><td style=\"text-align: right;\">0.213184</td><td style=\"text-align: right;\">              0.326066</td><td style=\"text-align: right;\">0.178739</td><td style=\"text-align: right;\">0.0319478</td></tr>\n",
       "<tr><td>GLM_1_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.848744</td><td style=\"text-align: right;\"> 0.123718</td><td style=\"text-align: right;\">0.198831</td><td style=\"text-align: right;\">              0.346984</td><td style=\"text-align: right;\">0.177685</td><td style=\"text-align: right;\">0.0315718</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_8         </td><td style=\"text-align: right;\">0.842631</td><td style=\"text-align: right;\"> 0.124233</td><td style=\"text-align: right;\">0.208981</td><td style=\"text-align: right;\">              0.352758</td><td style=\"text-align: right;\">0.176972</td><td style=\"text-align: right;\">0.0313192</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_7         </td><td style=\"text-align: right;\">0.840089</td><td style=\"text-align: right;\"> 0.126531</td><td style=\"text-align: right;\">0.195402</td><td style=\"text-align: right;\">              0.359213</td><td style=\"text-align: right;\">0.178401</td><td style=\"text-align: right;\">0.0318268</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200812_135538_model_3</td><td style=\"text-align: right;\">0.837065</td><td style=\"text-align: right;\"> 0.129292</td><td style=\"text-align: right;\">0.192153</td><td style=\"text-align: right;\">              0.326679</td><td style=\"text-align: right;\">0.179043</td><td style=\"text-align: right;\">0.0320564</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20200812_135538              </td><td style=\"text-align: right;\">0.835925</td><td style=\"text-align: right;\"> 0.127474</td><td style=\"text-align: right;\">0.188773</td><td style=\"text-align: right;\">              0.341284</td><td style=\"text-align: right;\">0.17856 </td><td style=\"text-align: right;\">0.0318837</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.835779</td><td style=\"text-align: right;\"> 0.127302</td><td style=\"text-align: right;\">0.190028</td><td style=\"text-align: right;\">              0.328931</td><td style=\"text-align: right;\">0.178697</td><td style=\"text-align: right;\">0.0319328</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.833233</td><td style=\"text-align: right;\"> 0.129255</td><td style=\"text-align: right;\">0.180142</td><td style=\"text-align: right;\">              0.334563</td><td style=\"text-align: right;\">0.179695</td><td style=\"text-align: right;\">0.0322902</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_6         </td><td style=\"text-align: right;\">0.832383</td><td style=\"text-align: right;\"> 0.127926</td><td style=\"text-align: right;\">0.183574</td><td style=\"text-align: right;\">              0.35257 </td><td style=\"text-align: right;\">0.179044</td><td style=\"text-align: right;\">0.0320568</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.832165</td><td style=\"text-align: right;\"> 0.128138</td><td style=\"text-align: right;\">0.185963</td><td style=\"text-align: right;\">              0.352079</td><td style=\"text-align: right;\">0.179   </td><td style=\"text-align: right;\">0.0320412</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_5         </td><td style=\"text-align: right;\">0.832034</td><td style=\"text-align: right;\"> 0.12932 </td><td style=\"text-align: right;\">0.183297</td><td style=\"text-align: right;\">              0.327457</td><td style=\"text-align: right;\">0.179483</td><td style=\"text-align: right;\">0.032214 </td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_135538_model_3</td><td style=\"text-align: right;\">0.830224</td><td style=\"text-align: right;\"> 0.135345</td><td style=\"text-align: right;\">0.212635</td><td style=\"text-align: right;\">              0.334057</td><td style=\"text-align: right;\">0.177215</td><td style=\"text-align: right;\">0.0314052</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_4         </td><td style=\"text-align: right;\">0.82915 </td><td style=\"text-align: right;\"> 0.130735</td><td style=\"text-align: right;\">0.175578</td><td style=\"text-align: right;\">              0.314606</td><td style=\"text-align: right;\">0.180497</td><td style=\"text-align: right;\">0.0325792</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.828363</td><td style=\"text-align: right;\"> 0.131608</td><td style=\"text-align: right;\">0.178534</td><td style=\"text-align: right;\">              0.366067</td><td style=\"text-align: right;\">0.18025 </td><td style=\"text-align: right;\">0.0324902</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_135538_model_2</td><td style=\"text-align: right;\">0.827745</td><td style=\"text-align: right;\"> 0.138807</td><td style=\"text-align: right;\">0.186529</td><td style=\"text-align: right;\">              0.312389</td><td style=\"text-align: right;\">0.181807</td><td style=\"text-align: right;\">0.0330537</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_1         </td><td style=\"text-align: right;\">0.826492</td><td style=\"text-align: right;\"> 0.137614</td><td style=\"text-align: right;\">0.176341</td><td style=\"text-align: right;\">              0.348893</td><td style=\"text-align: right;\">0.181007</td><td style=\"text-align: right;\">0.0327636</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.824975</td><td style=\"text-align: right;\"> 0.151603</td><td style=\"text-align: right;\">0.198113</td><td style=\"text-align: right;\">              0.341159</td><td style=\"text-align: right;\">0.177595</td><td style=\"text-align: right;\">0.0315399</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.823101</td><td style=\"text-align: right;\"> 0.135623</td><td style=\"text-align: right;\">0.17873 </td><td style=\"text-align: right;\">              0.344174</td><td style=\"text-align: right;\">0.180747</td><td style=\"text-align: right;\">0.0326697</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_2         </td><td style=\"text-align: right;\">0.820927</td><td style=\"text-align: right;\"> 0.136879</td><td style=\"text-align: right;\">0.170218</td><td style=\"text-align: right;\">              0.33462 </td><td style=\"text-align: right;\">0.181353</td><td style=\"text-align: right;\">0.0328889</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200812_135538_model_1</td><td style=\"text-align: right;\">0.820615</td><td style=\"text-align: right;\"> 0.187748</td><td style=\"text-align: right;\">0.15336 </td><td style=\"text-align: right;\">              0.355752</td><td style=\"text-align: right;\">0.193133</td><td style=\"text-align: right;\">0.0373004</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_3         </td><td style=\"text-align: right;\">0.82033 </td><td style=\"text-align: right;\"> 0.140096</td><td style=\"text-align: right;\">0.174458</td><td style=\"text-align: right;\">              0.333355</td><td style=\"text-align: right;\">0.181375</td><td style=\"text-align: right;\">0.0328971</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.812038</td><td style=\"text-align: right;\"> 0.136813</td><td style=\"text-align: right;\">0.174276</td><td style=\"text-align: right;\">              0.348415</td><td style=\"text-align: right;\">0.179308</td><td style=\"text-align: right;\">0.0321512</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200812_135538_model_2</td><td style=\"text-align: right;\">0.809518</td><td style=\"text-align: right;\"> 0.168652</td><td style=\"text-align: right;\">0.142146</td><td style=\"text-align: right;\">              0.350942</td><td style=\"text-align: right;\">0.18474 </td><td style=\"text-align: right;\">0.0341289</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_135538_model_1</td><td style=\"text-align: right;\">0.801366</td><td style=\"text-align: right;\"> 0.150641</td><td style=\"text-align: right;\">0.151367</td><td style=\"text-align: right;\">              0.353391</td><td style=\"text-align: right;\">0.190588</td><td style=\"text-align: right;\">0.0363238</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200812_135538_model_2</td><td style=\"text-align: right;\">0.785822</td><td style=\"text-align: right;\"> 0.179016</td><td style=\"text-align: right;\">0.1319  </td><td style=\"text-align: right;\">              0.356471</td><td style=\"text-align: right;\">0.191462</td><td style=\"text-align: right;\">0.0366577</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200812_135538_model_1</td><td style=\"text-align: right;\">0.768971</td><td style=\"text-align: right;\"> 0.310863</td><td style=\"text-align: right;\">0.120101</td><td style=\"text-align: right;\">              0.393601</td><td style=\"text-align: right;\">0.269703</td><td style=\"text-align: right;\">0.0727398</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can also print a leaderboard with the training time, in milliseconds, of each model and the time it takes each model to predict each row, in milliseconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">   aucpr</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">      mse</th><th style=\"text-align: right;\">  training_time_ms</th><th style=\"text-align: right;\">  predict_time_per_row_ms</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20200812_135538   </td><td style=\"text-align: right;\">0.85201 </td><td style=\"text-align: right;\"> 0.128657</td><td style=\"text-align: right;\">0.215807</td><td style=\"text-align: right;\">              0.331493</td><td style=\"text-align: right;\">0.178643</td><td style=\"text-align: right;\">0.0319133</td><td style=\"text-align: right;\">              5830</td><td style=\"text-align: right;\">                 0.081064</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20200812_135538</td><td style=\"text-align: right;\">0.849861</td><td style=\"text-align: right;\"> 0.128865</td><td style=\"text-align: right;\">0.213184</td><td style=\"text-align: right;\">              0.326066</td><td style=\"text-align: right;\">0.178739</td><td style=\"text-align: right;\">0.0319478</td><td style=\"text-align: right;\">              1308</td><td style=\"text-align: right;\">                 0.022333</td></tr>\n",
       "<tr><td>GLM_1_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.848744</td><td style=\"text-align: right;\"> 0.123718</td><td style=\"text-align: right;\">0.198831</td><td style=\"text-align: right;\">              0.346984</td><td style=\"text-align: right;\">0.177685</td><td style=\"text-align: right;\">0.0315718</td><td style=\"text-align: right;\">               822</td><td style=\"text-align: right;\">                 0.001128</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_8         </td><td style=\"text-align: right;\">0.842631</td><td style=\"text-align: right;\"> 0.124233</td><td style=\"text-align: right;\">0.208981</td><td style=\"text-align: right;\">              0.352758</td><td style=\"text-align: right;\">0.176972</td><td style=\"text-align: right;\">0.0313192</td><td style=\"text-align: right;\">               838</td><td style=\"text-align: right;\">                 0.005632</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_7         </td><td style=\"text-align: right;\">0.840089</td><td style=\"text-align: right;\"> 0.126531</td><td style=\"text-align: right;\">0.195402</td><td style=\"text-align: right;\">              0.359213</td><td style=\"text-align: right;\">0.178401</td><td style=\"text-align: right;\">0.0318268</td><td style=\"text-align: right;\">               728</td><td style=\"text-align: right;\">                 0.004074</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200812_135538_model_3</td><td style=\"text-align: right;\">0.837065</td><td style=\"text-align: right;\"> 0.129292</td><td style=\"text-align: right;\">0.192153</td><td style=\"text-align: right;\">              0.326679</td><td style=\"text-align: right;\">0.179043</td><td style=\"text-align: right;\">0.0320564</td><td style=\"text-align: right;\">              1236</td><td style=\"text-align: right;\">                 0.00342 </td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20200812_135538              </td><td style=\"text-align: right;\">0.835925</td><td style=\"text-align: right;\"> 0.127474</td><td style=\"text-align: right;\">0.188773</td><td style=\"text-align: right;\">              0.341284</td><td style=\"text-align: right;\">0.17856 </td><td style=\"text-align: right;\">0.0318837</td><td style=\"text-align: right;\">              1208</td><td style=\"text-align: right;\">                 0.002086</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.835779</td><td style=\"text-align: right;\"> 0.127302</td><td style=\"text-align: right;\">0.190028</td><td style=\"text-align: right;\">              0.328931</td><td style=\"text-align: right;\">0.178697</td><td style=\"text-align: right;\">0.0319328</td><td style=\"text-align: right;\">              1601</td><td style=\"text-align: right;\">                 0.003713</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.833233</td><td style=\"text-align: right;\"> 0.129255</td><td style=\"text-align: right;\">0.180142</td><td style=\"text-align: right;\">              0.334563</td><td style=\"text-align: right;\">0.179695</td><td style=\"text-align: right;\">0.0322902</td><td style=\"text-align: right;\">              1095</td><td style=\"text-align: right;\">                 0.003822</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_6         </td><td style=\"text-align: right;\">0.832383</td><td style=\"text-align: right;\"> 0.127926</td><td style=\"text-align: right;\">0.183574</td><td style=\"text-align: right;\">              0.35257 </td><td style=\"text-align: right;\">0.179044</td><td style=\"text-align: right;\">0.0320568</td><td style=\"text-align: right;\">               893</td><td style=\"text-align: right;\">                 0.004512</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.832165</td><td style=\"text-align: right;\"> 0.128138</td><td style=\"text-align: right;\">0.185963</td><td style=\"text-align: right;\">              0.352079</td><td style=\"text-align: right;\">0.179   </td><td style=\"text-align: right;\">0.0320412</td><td style=\"text-align: right;\">              1831</td><td style=\"text-align: right;\">                 0.005458</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_5         </td><td style=\"text-align: right;\">0.832034</td><td style=\"text-align: right;\"> 0.12932 </td><td style=\"text-align: right;\">0.183297</td><td style=\"text-align: right;\">              0.327457</td><td style=\"text-align: right;\">0.179483</td><td style=\"text-align: right;\">0.032214 </td><td style=\"text-align: right;\">               727</td><td style=\"text-align: right;\">                 0.003969</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_135538_model_3</td><td style=\"text-align: right;\">0.830224</td><td style=\"text-align: right;\"> 0.135345</td><td style=\"text-align: right;\">0.212635</td><td style=\"text-align: right;\">              0.334057</td><td style=\"text-align: right;\">0.177215</td><td style=\"text-align: right;\">0.0314052</td><td style=\"text-align: right;\">               718</td><td style=\"text-align: right;\">                 0.002793</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_4         </td><td style=\"text-align: right;\">0.82915 </td><td style=\"text-align: right;\"> 0.130735</td><td style=\"text-align: right;\">0.175578</td><td style=\"text-align: right;\">              0.314606</td><td style=\"text-align: right;\">0.180497</td><td style=\"text-align: right;\">0.0325792</td><td style=\"text-align: right;\">              1060</td><td style=\"text-align: right;\">                 0.003788</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.828363</td><td style=\"text-align: right;\"> 0.131608</td><td style=\"text-align: right;\">0.178534</td><td style=\"text-align: right;\">              0.366067</td><td style=\"text-align: right;\">0.18025 </td><td style=\"text-align: right;\">0.0324902</td><td style=\"text-align: right;\">               945</td><td style=\"text-align: right;\">                 0.003985</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_135538_model_2</td><td style=\"text-align: right;\">0.827745</td><td style=\"text-align: right;\"> 0.138807</td><td style=\"text-align: right;\">0.186529</td><td style=\"text-align: right;\">              0.312389</td><td style=\"text-align: right;\">0.181807</td><td style=\"text-align: right;\">0.0330537</td><td style=\"text-align: right;\">              3774</td><td style=\"text-align: right;\">                 0.015643</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_1         </td><td style=\"text-align: right;\">0.826492</td><td style=\"text-align: right;\"> 0.137614</td><td style=\"text-align: right;\">0.176341</td><td style=\"text-align: right;\">              0.348893</td><td style=\"text-align: right;\">0.181007</td><td style=\"text-align: right;\">0.0327636</td><td style=\"text-align: right;\">              1467</td><td style=\"text-align: right;\">                 0.005236</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.824975</td><td style=\"text-align: right;\"> 0.151603</td><td style=\"text-align: right;\">0.198113</td><td style=\"text-align: right;\">              0.341159</td><td style=\"text-align: right;\">0.177595</td><td style=\"text-align: right;\">0.0315399</td><td style=\"text-align: right;\">              1547</td><td style=\"text-align: right;\">                 0.006438</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.823101</td><td style=\"text-align: right;\"> 0.135623</td><td style=\"text-align: right;\">0.17873 </td><td style=\"text-align: right;\">              0.344174</td><td style=\"text-align: right;\">0.180747</td><td style=\"text-align: right;\">0.0326697</td><td style=\"text-align: right;\">              1306</td><td style=\"text-align: right;\">                 0.005006</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_2         </td><td style=\"text-align: right;\">0.820927</td><td style=\"text-align: right;\"> 0.136879</td><td style=\"text-align: right;\">0.170218</td><td style=\"text-align: right;\">              0.33462 </td><td style=\"text-align: right;\">0.181353</td><td style=\"text-align: right;\">0.0328889</td><td style=\"text-align: right;\">              1122</td><td style=\"text-align: right;\">                 0.00496 </td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200812_135538_model_1</td><td style=\"text-align: right;\">0.820615</td><td style=\"text-align: right;\"> 0.187748</td><td style=\"text-align: right;\">0.15336 </td><td style=\"text-align: right;\">              0.355752</td><td style=\"text-align: right;\">0.193133</td><td style=\"text-align: right;\">0.0373004</td><td style=\"text-align: right;\">             15821</td><td style=\"text-align: right;\">                 0.117215</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_135538_model_3         </td><td style=\"text-align: right;\">0.82033 </td><td style=\"text-align: right;\"> 0.140096</td><td style=\"text-align: right;\">0.174458</td><td style=\"text-align: right;\">              0.333355</td><td style=\"text-align: right;\">0.181375</td><td style=\"text-align: right;\">0.0328971</td><td style=\"text-align: right;\">              1916</td><td style=\"text-align: right;\">                 0.00745 </td></tr>\n",
       "<tr><td>XRT_1_AutoML_20200812_135538                       </td><td style=\"text-align: right;\">0.812038</td><td style=\"text-align: right;\"> 0.136813</td><td style=\"text-align: right;\">0.174276</td><td style=\"text-align: right;\">              0.348415</td><td style=\"text-align: right;\">0.179308</td><td style=\"text-align: right;\">0.0321512</td><td style=\"text-align: right;\">              2058</td><td style=\"text-align: right;\">                 0.010507</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200812_135538_model_2</td><td style=\"text-align: right;\">0.809518</td><td style=\"text-align: right;\"> 0.168652</td><td style=\"text-align: right;\">0.142146</td><td style=\"text-align: right;\">              0.350942</td><td style=\"text-align: right;\">0.18474 </td><td style=\"text-align: right;\">0.0341289</td><td style=\"text-align: right;\">             10796</td><td style=\"text-align: right;\">                 0.128548</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_135538_model_1</td><td style=\"text-align: right;\">0.801366</td><td style=\"text-align: right;\"> 0.150641</td><td style=\"text-align: right;\">0.151367</td><td style=\"text-align: right;\">              0.353391</td><td style=\"text-align: right;\">0.190588</td><td style=\"text-align: right;\">0.0363238</td><td style=\"text-align: right;\">              7883</td><td style=\"text-align: right;\">                 0.023264</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200812_135538_model_2</td><td style=\"text-align: right;\">0.785822</td><td style=\"text-align: right;\"> 0.179016</td><td style=\"text-align: right;\">0.1319  </td><td style=\"text-align: right;\">              0.356471</td><td style=\"text-align: right;\">0.191462</td><td style=\"text-align: right;\">0.0366577</td><td style=\"text-align: right;\">             12641</td><td style=\"text-align: right;\">                 0.074553</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200812_135538_model_1</td><td style=\"text-align: right;\">0.768971</td><td style=\"text-align: right;\"> 0.310863</td><td style=\"text-align: right;\">0.120101</td><td style=\"text-align: right;\">              0.393601</td><td style=\"text-align: right;\">0.269703</td><td style=\"text-align: right;\">0.0727398</td><td style=\"text-align: right;\">             14150</td><td style=\"text-align: right;\">                 0.067075</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.automl import get_leaderboard\n",
    "lb2 = get_leaderboard(aml, extra_columns='ALL')\n",
    "lb2.head(rows=lb2.nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the leaderboard, we can see that the best model is the Stacked Ensemble with the best model from each family, meaning that this model was built using the best model of each of the trained algorithms. This Ensemble will usually have a GLM, a Distributed Random Forest, Extremely-Randomized Forest, a GBM, and XGBoost, and Deep Learning model if you give it enough time to train all those models. Let's explore the coefficients of the metalearner to see the models in the Stacked Ensemble with their relative importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's retrieve the metalearner, and we can do it as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intercept': -4.180033392203896,\n",
       " 'GLM_1_AutoML_20200812_135538': 0.0,\n",
       " 'GBM_grid__1_AutoML_20200812_135538_model_8': 0.5416148940934792,\n",
       " 'DeepLearning_grid__2_AutoML_20200812_135538_model_3': 5.450841491109107,\n",
       " 'DRF_1_AutoML_20200812_135538': 4.046221096033774,\n",
       " 'XRT_1_AutoML_20200812_135538': 3.17959412522165}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model ids for all models in the AutoML Leaderboard\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "\n",
    "# Get the \"All Models\" Stacked Ensemble model\n",
    "se = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_BestOfFamily\" in mid][0])\n",
    "\n",
    "# Get the Stacked Ensemble metalearner model\n",
    "metalearner = h2o.get_model(se.metalearner()['name'])\n",
    "metalearner.coef()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanted to check this for the Ensemble with all the models, you will just simply change the name **StackedEnsemble_BestOfFamily** to **StackedEnsemble_AllModels** when saving the se variable in the code above.\n",
    "\n",
    "From the list above, we can see that the most important model used in our Stacked Ensemble is an XRT(Extremely Randomized Tree model, which is a variation of random forest). We can also plot the standardized coefficients with the following code (assuming you retrieved the metalearner from the step above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metalearner.std_coef_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how the best model performs on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomialGLM: stackedensemble\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.032409928215075774\n",
      "RMSE: 0.18002757626284863\n",
      "LogLoss: 0.1323640249003153\n",
      "Null degrees of freedom: 9941\n",
      "Residual degrees of freedom: 9933\n",
      "Null deviance: 3161.788933631878\n",
      "Residual deviance: 2631.92627111787\n",
      "AIC: 2649.92627111787\n",
      "AUC: 0.8443999107757988\n",
      "AUCPR: 0.23988545454219756\n",
      "Gini: 0.6887998215515976\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.0700597907128049: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FALSE</th>\n",
       "      <th>TRUE</th>\n",
       "      <th>Error</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FALSE</td>\n",
       "      <td>9142.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>(430.0/9572.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRUE</td>\n",
       "      <td>220.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.5946</td>\n",
       "      <td>(220.0/370.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Total</td>\n",
       "      <td>9362.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>(650.0/9942.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           FALSE   TRUE   Error             Rate\n",
       "0  FALSE  9142.0  430.0  0.0449   (430.0/9572.0)\n",
       "1   TRUE   220.0  150.0  0.5946    (220.0/370.0)\n",
       "2  Total  9362.0  580.0  0.0654   (650.0/9942.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>threshold</th>\n",
       "      <th>value</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max f1</td>\n",
       "      <td>0.070060</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max f2</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.388334</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max f0point5</td>\n",
       "      <td>0.160633</td>\n",
       "      <td>0.315871</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max accuracy</td>\n",
       "      <td>0.663143</td>\n",
       "      <td>0.963891</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max precision</td>\n",
       "      <td>0.881434</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>max recall</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>max specificity</td>\n",
       "      <td>0.981817</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>max absolute_mcc</td>\n",
       "      <td>0.070060</td>\n",
       "      <td>0.291131</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>max min_per_class_accuracy</td>\n",
       "      <td>0.025020</td>\n",
       "      <td>0.765253</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>max mean_per_class_accuracy</td>\n",
       "      <td>0.025485</td>\n",
       "      <td>0.767782</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max tns</td>\n",
       "      <td>0.981817</td>\n",
       "      <td>9571.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>max fns</td>\n",
       "      <td>0.981817</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max fps</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>9572.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>max tps</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>max tnr</td>\n",
       "      <td>0.981817</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>max fnr</td>\n",
       "      <td>0.981817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>max fpr</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>max tpr</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         metric  threshold        value    idx\n",
       "0                        max f1   0.070060     0.315789  230.0\n",
       "1                        max f2   0.031562     0.388334  313.0\n",
       "2                  max f0point5   0.160633     0.315871  147.0\n",
       "3                  max accuracy   0.663143     0.963891   21.0\n",
       "4                 max precision   0.881434     0.833333    5.0\n",
       "5                    max recall   0.015219     1.000000  398.0\n",
       "6               max specificity   0.981817     0.999896    0.0\n",
       "7              max absolute_mcc   0.070060     0.291131  230.0\n",
       "8    max min_per_class_accuracy   0.025020     0.765253  337.0\n",
       "9   max mean_per_class_accuracy   0.025485     0.767782  335.0\n",
       "10                      max tns   0.981817  9571.000000    0.0\n",
       "11                      max fns   0.981817   370.000000    0.0\n",
       "12                      max fps   0.015149  9572.000000  399.0\n",
       "13                      max tps   0.015219   370.000000  398.0\n",
       "14                      max tnr   0.981817     0.999896    0.0\n",
       "15                      max fnr   0.981817     1.000000    0.0\n",
       "16                      max fpr   0.015149     1.000000  399.0\n",
       "17                      max tpr   0.015219     1.000000  398.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate:  3.72 %, avg score:  3.26 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>cumulative_data_fraction</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>lift</th>\n",
       "      <th>cumulative_lift</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>score</th>\n",
       "      <th>cumulative_response_rate</th>\n",
       "      <th>cumulative_score</th>\n",
       "      <th>capture_rate</th>\n",
       "      <th>cumulative_capture_rate</th>\n",
       "      <th>gain</th>\n",
       "      <th>cumulative_gain</th>\n",
       "      <th>kolmogorov_smirnov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.319650</td>\n",
       "      <td>11.554216</td>\n",
       "      <td>11.554216</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.548551</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.548551</td>\n",
       "      <td>0.116216</td>\n",
       "      <td>0.116216</td>\n",
       "      <td>1055.421622</td>\n",
       "      <td>1055.421622</td>\n",
       "      <td>0.110261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.020016</td>\n",
       "      <td>0.184518</td>\n",
       "      <td>7.599672</td>\n",
       "      <td>9.586880</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.239019</td>\n",
       "      <td>0.356784</td>\n",
       "      <td>0.394563</td>\n",
       "      <td>0.075676</td>\n",
       "      <td>0.191892</td>\n",
       "      <td>659.967240</td>\n",
       "      <td>858.688035</td>\n",
       "      <td>0.178520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.030074</td>\n",
       "      <td>0.128113</td>\n",
       "      <td>5.642757</td>\n",
       "      <td>8.267775</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.153236</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.313852</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.248649</td>\n",
       "      <td>464.275676</td>\n",
       "      <td>726.777547</td>\n",
       "      <td>0.227023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.040032</td>\n",
       "      <td>0.095541</td>\n",
       "      <td>4.342670</td>\n",
       "      <td>7.291430</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.111045</td>\n",
       "      <td>0.271357</td>\n",
       "      <td>0.263405</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.291892</td>\n",
       "      <td>334.266994</td>\n",
       "      <td>629.143012</td>\n",
       "      <td>0.261595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050091</td>\n",
       "      <td>0.080742</td>\n",
       "      <td>6.717568</td>\n",
       "      <td>7.176197</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.087652</td>\n",
       "      <td>0.267068</td>\n",
       "      <td>0.228113</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.359459</td>\n",
       "      <td>571.756757</td>\n",
       "      <td>617.619668</td>\n",
       "      <td>0.321327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.100080</td>\n",
       "      <td>0.045972</td>\n",
       "      <td>2.757311</td>\n",
       "      <td>4.968975</td>\n",
       "      <td>0.102616</td>\n",
       "      <td>0.059070</td>\n",
       "      <td>0.184925</td>\n",
       "      <td>0.143676</td>\n",
       "      <td>0.137838</td>\n",
       "      <td>0.497297</td>\n",
       "      <td>175.731144</td>\n",
       "      <td>396.897460</td>\n",
       "      <td>0.412571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.150070</td>\n",
       "      <td>0.034969</td>\n",
       "      <td>2.432922</td>\n",
       "      <td>4.124190</td>\n",
       "      <td>0.090543</td>\n",
       "      <td>0.039903</td>\n",
       "      <td>0.153485</td>\n",
       "      <td>0.109108</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.618919</td>\n",
       "      <td>143.292186</td>\n",
       "      <td>312.419028</td>\n",
       "      <td>0.486972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.200060</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>1.892273</td>\n",
       "      <td>3.566491</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.031431</td>\n",
       "      <td>0.132730</td>\n",
       "      <td>0.089699</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.713514</td>\n",
       "      <td>89.227255</td>\n",
       "      <td>256.649138</td>\n",
       "      <td>0.533300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.300040</td>\n",
       "      <td>0.022684</td>\n",
       "      <td>0.946136</td>\n",
       "      <td>2.693332</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.025304</td>\n",
       "      <td>0.100235</td>\n",
       "      <td>0.068241</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.808108</td>\n",
       "      <td>-5.386372</td>\n",
       "      <td>169.333249</td>\n",
       "      <td>0.527707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.400020</td>\n",
       "      <td>0.019795</td>\n",
       "      <td>0.756909</td>\n",
       "      <td>2.209348</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.021102</td>\n",
       "      <td>0.082223</td>\n",
       "      <td>0.056459</td>\n",
       "      <td>0.075676</td>\n",
       "      <td>0.883784</td>\n",
       "      <td>-24.309098</td>\n",
       "      <td>120.934835</td>\n",
       "      <td>0.502463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.405487</td>\n",
       "      <td>1.848649</td>\n",
       "      <td>0.015091</td>\n",
       "      <td>0.018830</td>\n",
       "      <td>0.068799</td>\n",
       "      <td>0.048935</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.924324</td>\n",
       "      <td>-59.451302</td>\n",
       "      <td>84.864865</td>\n",
       "      <td>0.440726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.599980</td>\n",
       "      <td>0.017041</td>\n",
       "      <td>0.324390</td>\n",
       "      <td>1.594648</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.017528</td>\n",
       "      <td>0.059346</td>\n",
       "      <td>0.043701</td>\n",
       "      <td>0.032432</td>\n",
       "      <td>0.956757</td>\n",
       "      <td>-67.561042</td>\n",
       "      <td>59.464806</td>\n",
       "      <td>0.370568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.699960</td>\n",
       "      <td>0.016351</td>\n",
       "      <td>0.135162</td>\n",
       "      <td>1.386180</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>0.051588</td>\n",
       "      <td>0.039840</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.970270</td>\n",
       "      <td>-86.483767</td>\n",
       "      <td>38.618006</td>\n",
       "      <td>0.280759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.799940</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.081097</td>\n",
       "      <td>1.223065</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.016092</td>\n",
       "      <td>0.045517</td>\n",
       "      <td>0.036872</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.978378</td>\n",
       "      <td>-91.890260</td>\n",
       "      <td>22.306524</td>\n",
       "      <td>0.185336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.899920</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>0.162195</td>\n",
       "      <td>1.105204</td>\n",
       "      <td>0.006036</td>\n",
       "      <td>0.015655</td>\n",
       "      <td>0.041131</td>\n",
       "      <td>0.034515</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.994595</td>\n",
       "      <td>-83.780521</td>\n",
       "      <td>10.520392</td>\n",
       "      <td>0.098335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>0.054011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.037216</td>\n",
       "      <td>0.032588</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-94.598941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    group  cumulative_data_fraction  lower_threshold       lift  \\\n",
       "0       1                  0.010058         0.319650  11.554216   \n",
       "1       2                  0.020016         0.184518   7.599672   \n",
       "2       3                  0.030074         0.128113   5.642757   \n",
       "3       4                  0.040032         0.095541   4.342670   \n",
       "4       5                  0.050091         0.080742   6.717568   \n",
       "5       6                  0.100080         0.045972   2.757311   \n",
       "6       7                  0.150070         0.034969   2.432922   \n",
       "7       8                  0.200060         0.028667   1.892273   \n",
       "8       9                  0.300040         0.022684   0.946136   \n",
       "9      10                  0.400020         0.019795   0.756909   \n",
       "10     11                  0.500000         0.018066   0.405487   \n",
       "11     12                  0.599980         0.017041   0.324390   \n",
       "12     13                  0.699960         0.016351   0.135162   \n",
       "13     14                  0.799940         0.015850   0.081097   \n",
       "14     15                  0.899920         0.015448   0.162195   \n",
       "15     16                  1.000000         0.015106   0.054011   \n",
       "\n",
       "    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n",
       "0         11.554216       0.430000  0.548551                  0.430000   \n",
       "1          9.586880       0.282828  0.239019                  0.356784   \n",
       "2          8.267775       0.210000  0.153236                  0.307692   \n",
       "3          7.291430       0.161616  0.111045                  0.271357   \n",
       "4          7.176197       0.250000  0.087652                  0.267068   \n",
       "5          4.968975       0.102616  0.059070                  0.184925   \n",
       "6          4.124190       0.090543  0.039903                  0.153485   \n",
       "7          3.566491       0.070423  0.031431                  0.132730   \n",
       "8          2.693332       0.035211  0.025304                  0.100235   \n",
       "9          2.209348       0.028169  0.021102                  0.082223   \n",
       "10         1.848649       0.015091  0.018830                  0.068799   \n",
       "11         1.594648       0.012072  0.017528                  0.059346   \n",
       "12         1.386180       0.005030  0.016669                  0.051588   \n",
       "13         1.223065       0.003018  0.016092                  0.045517   \n",
       "14         1.105204       0.006036  0.015655                  0.041131   \n",
       "15         1.000000       0.002010  0.015262                  0.037216   \n",
       "\n",
       "    cumulative_score  capture_rate  cumulative_capture_rate         gain  \\\n",
       "0           0.548551      0.116216                 0.116216  1055.421622   \n",
       "1           0.394563      0.075676                 0.191892   659.967240   \n",
       "2           0.313852      0.056757                 0.248649   464.275676   \n",
       "3           0.263405      0.043243                 0.291892   334.266994   \n",
       "4           0.228113      0.067568                 0.359459   571.756757   \n",
       "5           0.143676      0.137838                 0.497297   175.731144   \n",
       "6           0.109108      0.121622                 0.618919   143.292186   \n",
       "7           0.089699      0.094595                 0.713514    89.227255   \n",
       "8           0.068241      0.094595                 0.808108    -5.386372   \n",
       "9           0.056459      0.075676                 0.883784   -24.309098   \n",
       "10          0.048935      0.040541                 0.924324   -59.451302   \n",
       "11          0.043701      0.032432                 0.956757   -67.561042   \n",
       "12          0.039840      0.013514                 0.970270   -86.483767   \n",
       "13          0.036872      0.008108                 0.978378   -91.890260   \n",
       "14          0.034515      0.016216                 0.994595   -83.780521   \n",
       "15          0.032588      0.005405                 1.000000   -94.598941   \n",
       "\n",
       "    cumulative_gain  kolmogorov_smirnov  \n",
       "0       1055.421622            0.110261  \n",
       "1        858.688035            0.178520  \n",
       "2        726.777547            0.227023  \n",
       "3        629.143012            0.261595  \n",
       "4        617.619668            0.321327  \n",
       "5        396.897460            0.412571  \n",
       "6        312.419028            0.486972  \n",
       "7        256.649138            0.533300  \n",
       "8        169.333249            0.527707  \n",
       "9        120.934835            0.502463  \n",
       "10        84.864865            0.440726  \n",
       "11        59.464806            0.370568  \n",
       "12        38.618006            0.280759  \n",
       "13        22.306524            0.185336  \n",
       "14        10.520392            0.098335  \n",
       "15         0.000000            0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.model_performance(test_data=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the results, we can see that in fifteen minutes, and with less data, AutoML obtained scores somewhat close to what we obtained in the first tutorial. The AUC that we obtained was 0.828. Although this is a good AUC, because we have a very imbalanced dataset, we must also look at the misclassification errors for both classes. As you can see, our model is having a hard time classifying bad loans; this is mainly due because only about 3.6% of loans are labeled as bad loans. However, the model is doing very well when classifying good loans; although it is still far from being the best model, this gives us a solid starting point. Even though we set balance _lasses=True, we just tried a quick under-over sampling ratio. If we were to find the right value and gave AutoML more time, we could potentially improve the misclassification error for the bad_loan or predicted TRUE class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "aml.leader.model_performance(test_data=test).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it's the same AUC value that we obtained in the model summary, but the plot helps us visualize it better.\n",
    "\n",
    "Lastly, let's make some predictions on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>predict  </th><th style=\"text-align: right;\">   FALSE</th><th style=\"text-align: right;\">     TRUE</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.983562</td><td style=\"text-align: right;\">0.0164383</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.960454</td><td style=\"text-align: right;\">0.039546 </td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.979351</td><td style=\"text-align: right;\">0.0206494</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.977953</td><td style=\"text-align: right;\">0.0220471</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.963207</td><td style=\"text-align: right;\">0.0367931</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.980323</td><td style=\"text-align: right;\">0.0196766</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.984581</td><td style=\"text-align: right;\">0.0154186</td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.983023</td><td style=\"text-align: right;\">0.0169775</td></tr>\n",
       "<tr><td>TRUE     </td><td style=\"text-align: right;\">0.768001</td><td style=\"text-align: right;\">0.231999 </td></tr>\n",
       "<tr><td>FALSE    </td><td style=\"text-align: right;\">0.984178</td><td style=\"text-align: right;\">0.0158217</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned in the first tutorial, the predictions we get are based on a probability. In the frame above, we have a probability for FALSE,, and another one for TRUE. The prediction, predict, is based on the threshold that maximizes the F1 score. For example, the threshold that maximizes the F1 is about 0.1061, meaning that if the probability of TRUE is greater than the threshold, the predicted label would be TRUE.\n",
    "\n",
    "After exploring the results for our classification problem, let's use AutoML to explore a regression use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. H2O AutoML Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our regression use-case, we are using the same dataset and the same training and test sets. But we do need to choose our predictors and response columns, and we will do it as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reg = \"ORIGINAL_INTEREST_RATE\"\n",
    "\n",
    "ignore_reg = [\"ORIGINAL_INTEREST_RATE\", \"FIRST_PAYMENT_DATE\", \"MATURITY_DATE\", \"MORTGAGE_INSURANCE_PERCENTAGE\", \"PREPAYMENT_PENALTY_MORTGAGE_FLAG\", \"LOAN_SEQUENCE_NUMBER\", \"PREPAID\", \"DELINQUENT\", \"PRODUCT_TYPE\"] \n",
    "\n",
    "x_reg = list(set(train.names) - set(ignore_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start our second AutoML model and train it. This time we will use a time constrain, and set max_runtime_secs to 900 seconds, or 15 minutes. Again, we set max_runtime_secs_per_model to 30 seconds. You will notice that we are specifying the stopping metric and also the sort metric. In the second tutorial, we focused on RMSE and MAE to check the performance of our model, and we noticed that the two values seemed very correlated. For that reason, we could use any of those metrics. We will use the RMSE for early stopping because it penalizes the error more than the MAE, and we will also use it to sort the leaderboard based on the best value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "AutoML progress: |\n",
      "14:29:11.802: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml = H2OAutoML(max_runtime_secs=900, \n",
    "                max_runtime_secs_per_model=30, \n",
    "                seed=623, \n",
    "                project_name='regression', \n",
    "                stopping_metric=\"RMSE\", \n",
    "                sort_metric=\"RMSE\")\n",
    "\n",
    "%time \n",
    "aml.train(x=x_reg, y=y_reg, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">     mae</th><th style=\"text-align: right;\">    rmsle</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_2_AutoML_20200812_142911                       </td><td style=\"text-align: right;\">0.428265</td><td style=\"text-align: right;\">                0.183411</td><td style=\"text-align: right;\">0.183411</td><td style=\"text-align: right;\">0.311863</td><td style=\"text-align: right;\">0.0506688</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_142911_model_8         </td><td style=\"text-align: right;\">0.428337</td><td style=\"text-align: right;\">                0.183473</td><td style=\"text-align: right;\">0.183473</td><td style=\"text-align: right;\">0.311138</td><td style=\"text-align: right;\">0.050679 </td></tr>\n",
       "<tr><td>GBM_3_AutoML_20200812_142911                       </td><td style=\"text-align: right;\">0.428621</td><td style=\"text-align: right;\">                0.183716</td><td style=\"text-align: right;\">0.183716</td><td style=\"text-align: right;\">0.311637</td><td style=\"text-align: right;\">0.0506949</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20200812_142911                       </td><td style=\"text-align: right;\">0.429201</td><td style=\"text-align: right;\">                0.184213</td><td style=\"text-align: right;\">0.184213</td><td style=\"text-align: right;\">0.313097</td><td style=\"text-align: right;\">0.0508055</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20200812_142911                       </td><td style=\"text-align: right;\">0.429429</td><td style=\"text-align: right;\">                0.184409</td><td style=\"text-align: right;\">0.184409</td><td style=\"text-align: right;\">0.313175</td><td style=\"text-align: right;\">0.0508044</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_142911_model_7         </td><td style=\"text-align: right;\">0.429573</td><td style=\"text-align: right;\">                0.184533</td><td style=\"text-align: right;\">0.184533</td><td style=\"text-align: right;\">0.313894</td><td style=\"text-align: right;\">0.0508162</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20200812_142911                       </td><td style=\"text-align: right;\">0.430283</td><td style=\"text-align: right;\">                0.185144</td><td style=\"text-align: right;\">0.185144</td><td style=\"text-align: right;\">0.313212</td><td style=\"text-align: right;\">0.0508986</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_142911_model_6         </td><td style=\"text-align: right;\">0.430743</td><td style=\"text-align: right;\">                0.185539</td><td style=\"text-align: right;\">0.185539</td><td style=\"text-align: right;\">0.315183</td><td style=\"text-align: right;\">0.0509298</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_142911_model_1         </td><td style=\"text-align: right;\">0.430833</td><td style=\"text-align: right;\">                0.185617</td><td style=\"text-align: right;\">0.185617</td><td style=\"text-align: right;\">0.312861</td><td style=\"text-align: right;\">0.0509754</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_142911_model_3         </td><td style=\"text-align: right;\">0.431312</td><td style=\"text-align: right;\">                0.18603 </td><td style=\"text-align: right;\">0.18603 </td><td style=\"text-align: right;\">0.312872</td><td style=\"text-align: right;\">0.051025 </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_142911_model_4         </td><td style=\"text-align: right;\">0.431731</td><td style=\"text-align: right;\">                0.186392</td><td style=\"text-align: right;\">0.186392</td><td style=\"text-align: right;\">0.315049</td><td style=\"text-align: right;\">0.0510746</td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20200812_142911   </td><td style=\"text-align: right;\">0.435784</td><td style=\"text-align: right;\">                0.189907</td><td style=\"text-align: right;\">0.189907</td><td style=\"text-align: right;\">0.320011</td><td style=\"text-align: right;\">0.0514471</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20200812_142911                       </td><td style=\"text-align: right;\">0.435872</td><td style=\"text-align: right;\">                0.189985</td><td style=\"text-align: right;\">0.189985</td><td style=\"text-align: right;\">0.316027</td><td style=\"text-align: right;\">0.0515223</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20200812_142911</td><td style=\"text-align: right;\">0.438123</td><td style=\"text-align: right;\">                0.191952</td><td style=\"text-align: right;\">0.191952</td><td style=\"text-align: right;\">0.322266</td><td style=\"text-align: right;\">0.0517073</td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_142911_model_2         </td><td style=\"text-align: right;\">0.438937</td><td style=\"text-align: right;\">                0.192666</td><td style=\"text-align: right;\">0.192666</td><td style=\"text-align: right;\">0.319025</td><td style=\"text-align: right;\">0.051979 </td></tr>\n",
       "<tr><td>GBM_grid__1_AutoML_20200812_142911_model_5         </td><td style=\"text-align: right;\">0.439653</td><td style=\"text-align: right;\">                0.193295</td><td style=\"text-align: right;\">0.193295</td><td style=\"text-align: right;\">0.324049</td><td style=\"text-align: right;\">0.0519463</td></tr>\n",
       "<tr><td>GLM_1_AutoML_20200812_142911                       </td><td style=\"text-align: right;\">0.456864</td><td style=\"text-align: right;\">                0.208725</td><td style=\"text-align: right;\">0.208725</td><td style=\"text-align: right;\">0.340086</td><td style=\"text-align: right;\">0.0540339</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20200812_142911                       </td><td style=\"text-align: right;\">0.46102 </td><td style=\"text-align: right;\">                0.21254 </td><td style=\"text-align: right;\">0.21254 </td><td style=\"text-align: right;\">0.33914 </td><td style=\"text-align: right;\">0.0542975</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20200812_142911              </td><td style=\"text-align: right;\">0.467853</td><td style=\"text-align: right;\">                0.218887</td><td style=\"text-align: right;\">0.218887</td><td style=\"text-align: right;\">0.336216</td><td style=\"text-align: right;\">0.0551956</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_142911_model_1</td><td style=\"text-align: right;\">0.478177</td><td style=\"text-align: right;\">                0.228653</td><td style=\"text-align: right;\">0.228653</td><td style=\"text-align: right;\">0.341727</td><td style=\"text-align: right;\">0.056274 </td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_142911_model_4</td><td style=\"text-align: right;\">0.480472</td><td style=\"text-align: right;\">                0.230854</td><td style=\"text-align: right;\">0.230854</td><td style=\"text-align: right;\">0.344352</td><td style=\"text-align: right;\">0.0565939</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_142911_model_3</td><td style=\"text-align: right;\">0.482282</td><td style=\"text-align: right;\">                0.232595</td><td style=\"text-align: right;\">0.232595</td><td style=\"text-align: right;\">0.349689</td><td style=\"text-align: right;\">0.0567661</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200812_142911_model_1</td><td style=\"text-align: right;\">0.503165</td><td style=\"text-align: right;\">                0.253175</td><td style=\"text-align: right;\">0.253175</td><td style=\"text-align: right;\">0.35881 </td><td style=\"text-align: right;\">0.0592603</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200812_142911_model_2</td><td style=\"text-align: right;\">0.537896</td><td style=\"text-align: right;\">                0.289332</td><td style=\"text-align: right;\">0.289332</td><td style=\"text-align: right;\">0.393232</td><td style=\"text-align: right;\">0.063531 </td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_142911_model_2</td><td style=\"text-align: right;\">0.538313</td><td style=\"text-align: right;\">                0.289781</td><td style=\"text-align: right;\">0.289781</td><td style=\"text-align: right;\">0.399307</td><td style=\"text-align: right;\">0.0636793</td></tr>\n",
       "<tr><td>DeepLearning_grid__1_AutoML_20200812_142911_model_5</td><td style=\"text-align: right;\">0.544794</td><td style=\"text-align: right;\">                0.296801</td><td style=\"text-align: right;\">0.296801</td><td style=\"text-align: right;\">0.412039</td><td style=\"text-align: right;\">0.0645979</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200812_142911_model_3</td><td style=\"text-align: right;\">0.575871</td><td style=\"text-align: right;\">                0.331628</td><td style=\"text-align: right;\">0.331628</td><td style=\"text-align: right;\">0.439756</td><td style=\"text-align: right;\">0.0681739</td></tr>\n",
       "<tr><td>DeepLearning_grid__3_AutoML_20200812_142911_model_2</td><td style=\"text-align: right;\">0.602184</td><td style=\"text-align: right;\">                0.362625</td><td style=\"text-align: right;\">0.362625</td><td style=\"text-align: right;\">0.460706</td><td style=\"text-align: right;\">0.0713204</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200812_142911_model_3</td><td style=\"text-align: right;\">0.638034</td><td style=\"text-align: right;\">                0.407087</td><td style=\"text-align: right;\">0.407087</td><td style=\"text-align: right;\">0.518046</td><td style=\"text-align: right;\">0.0761774</td></tr>\n",
       "<tr><td>DeepLearning_grid__2_AutoML_20200812_142911_model_1</td><td style=\"text-align: right;\">0.65293 </td><td style=\"text-align: right;\">                0.426317</td><td style=\"text-align: right;\">0.426317</td><td style=\"text-align: right;\">0.506999</td><td style=\"text-align: right;\">0.0773377</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leaderboard shows that the GBM models clearly dominated this task. We can retrieve the best model with the model.leader command; but, what if we wanted to get another model from our leaderboard? One way to do so is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model ids for all models in the AutoML Leaderboard\n",
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "\n",
    "# Get the top GBM model\n",
    "gbm = h2o.get_model([mid for mid in model_ids if \"GBM_3\" in mid][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GBM_2_AutoML_20200812_142911',\n",
       " 'GBM_grid__1_AutoML_20200812_142911_model_8',\n",
       " 'GBM_3_AutoML_20200812_142911',\n",
       " 'GBM_5_AutoML_20200812_142911',\n",
       " 'GBM_1_AutoML_20200812_142911',\n",
       " 'GBM_grid__1_AutoML_20200812_142911_model_7',\n",
       " 'GBM_4_AutoML_20200812_142911',\n",
       " 'GBM_grid__1_AutoML_20200812_142911_model_6',\n",
       " 'GBM_grid__1_AutoML_20200812_142911_model_1',\n",
       " 'GBM_grid__1_AutoML_20200812_142911_model_3',\n",
       " 'GBM_grid__1_AutoML_20200812_142911_model_4',\n",
       " 'StackedEnsemble_AllModels_AutoML_20200812_142911',\n",
       " 'DRF_1_AutoML_20200812_142911',\n",
       " 'StackedEnsemble_BestOfFamily_AutoML_20200812_142911',\n",
       " 'GBM_grid__1_AutoML_20200812_142911_model_2',\n",
       " 'GBM_grid__1_AutoML_20200812_142911_model_5',\n",
       " 'GLM_1_AutoML_20200812_142911',\n",
       " 'XRT_1_AutoML_20200812_142911',\n",
       " 'DeepLearning_1_AutoML_20200812_142911',\n",
       " 'DeepLearning_grid__1_AutoML_20200812_142911_model_1',\n",
       " 'DeepLearning_grid__1_AutoML_20200812_142911_model_4',\n",
       " 'DeepLearning_grid__1_AutoML_20200812_142911_model_3',\n",
       " 'DeepLearning_grid__3_AutoML_20200812_142911_model_1',\n",
       " 'DeepLearning_grid__2_AutoML_20200812_142911_model_2',\n",
       " 'DeepLearning_grid__1_AutoML_20200812_142911_model_2',\n",
       " 'DeepLearning_grid__1_AutoML_20200812_142911_model_5',\n",
       " 'DeepLearning_grid__3_AutoML_20200812_142911_model_3',\n",
       " 'DeepLearning_grid__3_AutoML_20200812_142911_model_2',\n",
       " 'DeepLearning_grid__2_AutoML_20200812_142911_model_3',\n",
       " 'DeepLearning_grid__2_AutoML_20200812_142911_model_1']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you would need to change the name **GBM_3**, in the code above, to the name of the model that you want, and that should retrieve the desired model. For example, if you wanted to get the best XGBoost in the leaderboard, you would need to make the following change (you do not need to run the following line of code, this is just an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble\" in mid][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have retrieved the best model, we can take a look at some of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntrees =  {'default': 50, 'actual': 64, 'input': 10000}\n",
      "max depth =  {'default': 5, 'actual': 8, 'input': 8}\n",
      "learn rate =  {'default': 0.1, 'actual': 0.1, 'input': 0.1}\n",
      "sample rate =  {'default': 1.0, 'actual': 0.8, 'input': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print(\"ntrees = \", gbm.params['ntrees'])\n",
    "print(\"max depth = \", gbm.params['max_depth'])\n",
    "print(\"learn rate = \", gbm.params['learn_rate'])\n",
    "print(\"sample rate = \", gbm.params['sample_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_3_AutoML_20200812_142911\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>number_of_internal_trees</th>\n",
       "      <th>model_size_in_bytes</th>\n",
       "      <th>min_depth</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>max_leaves</th>\n",
       "      <th>mean_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>156285.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>148.82812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n",
       "0               64.0                      64.0             156285.0   \n",
       "\n",
       "   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n",
       "0        8.0        8.0         8.0        58.0       214.0    148.82812  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.13595945090894726\n",
      "RMSE: 0.3687267971126417\n",
      "MAE: 0.2669786134576564\n",
      "RMSLE: 0.0437219571364214\n",
      "Mean Residual Deviance: 0.13595945090894726\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.1837159842191993\n",
      "RMSE: 0.4286210263381853\n",
      "MAE: 0.31163694450398555\n",
      "RMSLE: 0.0506949417738023\n",
      "Mean Residual Deviance: 0.1837159842191993\n",
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>cv_1_valid</th>\n",
       "      <th>cv_2_valid</th>\n",
       "      <th>cv_3_valid</th>\n",
       "      <th>cv_4_valid</th>\n",
       "      <th>cv_5_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mae</td>\n",
       "      <td>0.31163692</td>\n",
       "      <td>7.7659625E-4</td>\n",
       "      <td>0.31149286</td>\n",
       "      <td>0.3129312</td>\n",
       "      <td>0.31112084</td>\n",
       "      <td>0.31096697</td>\n",
       "      <td>0.31167278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean_residual_deviance</td>\n",
       "      <td>0.18371594</td>\n",
       "      <td>0.0015572766</td>\n",
       "      <td>0.18277213</td>\n",
       "      <td>0.1861775</td>\n",
       "      <td>0.18369487</td>\n",
       "      <td>0.18206488</td>\n",
       "      <td>0.18387036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mse</td>\n",
       "      <td>0.18371594</td>\n",
       "      <td>0.0015572766</td>\n",
       "      <td>0.18277213</td>\n",
       "      <td>0.1861775</td>\n",
       "      <td>0.18369487</td>\n",
       "      <td>0.18206488</td>\n",
       "      <td>0.18387036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2</td>\n",
       "      <td>0.4609645</td>\n",
       "      <td>0.0056585274</td>\n",
       "      <td>0.46189997</td>\n",
       "      <td>0.45222977</td>\n",
       "      <td>0.46615866</td>\n",
       "      <td>0.46547118</td>\n",
       "      <td>0.45906293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>residual_deviance</td>\n",
       "      <td>0.18371594</td>\n",
       "      <td>0.0015572766</td>\n",
       "      <td>0.18277213</td>\n",
       "      <td>0.1861775</td>\n",
       "      <td>0.18369487</td>\n",
       "      <td>0.18206488</td>\n",
       "      <td>0.18387036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rmse</td>\n",
       "      <td>0.42861792</td>\n",
       "      <td>0.0018142059</td>\n",
       "      <td>0.42751858</td>\n",
       "      <td>0.4314829</td>\n",
       "      <td>0.4285964</td>\n",
       "      <td>0.4266906</td>\n",
       "      <td>0.42880106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rmsle</td>\n",
       "      <td>0.050694704</td>\n",
       "      <td>1.7132562E-4</td>\n",
       "      <td>0.05055868</td>\n",
       "      <td>0.050952785</td>\n",
       "      <td>0.05077792</td>\n",
       "      <td>0.050545648</td>\n",
       "      <td>0.050638497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  mean            sd  cv_1_valid   cv_2_valid  \\\n",
       "0                     mae   0.31163692  7.7659625E-4  0.31149286    0.3129312   \n",
       "1  mean_residual_deviance   0.18371594  0.0015572766  0.18277213    0.1861775   \n",
       "2                     mse   0.18371594  0.0015572766  0.18277213    0.1861775   \n",
       "3                      r2    0.4609645  0.0056585274  0.46189997   0.45222977   \n",
       "4       residual_deviance   0.18371594  0.0015572766  0.18277213    0.1861775   \n",
       "5                    rmse   0.42861792  0.0018142059  0.42751858    0.4314829   \n",
       "6                   rmsle  0.050694704  1.7132562E-4  0.05055868  0.050952785   \n",
       "\n",
       "   cv_3_valid   cv_4_valid   cv_5_valid  \n",
       "0  0.31112084   0.31096697   0.31167278  \n",
       "1  0.18369487   0.18206488   0.18387036  \n",
       "2  0.18369487   0.18206488   0.18387036  \n",
       "3  0.46615866   0.46547118   0.45906293  \n",
       "4  0.18369487   0.18206488   0.18387036  \n",
       "5   0.4285964    0.4266906   0.42880106  \n",
       "6  0.05077792  0.050545648  0.050638497  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_mae</th>\n",
       "      <th>training_deviance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:15</td>\n",
       "      <td>15.915 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583814</td>\n",
       "      <td>0.441436</td>\n",
       "      <td>0.340839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:15</td>\n",
       "      <td>16.079 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.504835</td>\n",
       "      <td>0.380336</td>\n",
       "      <td>0.254859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:15</td>\n",
       "      <td>16.242 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.463384</td>\n",
       "      <td>0.346920</td>\n",
       "      <td>0.214725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:15</td>\n",
       "      <td>16.400 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.436223</td>\n",
       "      <td>0.323910</td>\n",
       "      <td>0.190291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:15</td>\n",
       "      <td>16.557 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.418665</td>\n",
       "      <td>0.308798</td>\n",
       "      <td>0.175280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:15</td>\n",
       "      <td>16.706 sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.406488</td>\n",
       "      <td>0.298305</td>\n",
       "      <td>0.165232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:16</td>\n",
       "      <td>16.854 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.397875</td>\n",
       "      <td>0.290840</td>\n",
       "      <td>0.158305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:16</td>\n",
       "      <td>17.006 sec</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.391741</td>\n",
       "      <td>0.285448</td>\n",
       "      <td>0.153461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:16</td>\n",
       "      <td>17.158 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.386023</td>\n",
       "      <td>0.280814</td>\n",
       "      <td>0.149013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:16</td>\n",
       "      <td>17.314 sec</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.381194</td>\n",
       "      <td>0.276746</td>\n",
       "      <td>0.145309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:16</td>\n",
       "      <td>17.472 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.376532</td>\n",
       "      <td>0.273171</td>\n",
       "      <td>0.141776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:16</td>\n",
       "      <td>17.598 sec</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.373529</td>\n",
       "      <td>0.270779</td>\n",
       "      <td>0.139524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:16</td>\n",
       "      <td>17.722 sec</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.370934</td>\n",
       "      <td>0.268805</td>\n",
       "      <td>0.137592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2020-08-12 14:30:17</td>\n",
       "      <td>17.828 sec</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.368727</td>\n",
       "      <td>0.266979</td>\n",
       "      <td>0.135959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2020-08-12 14:30:15  15.915 sec              0.0       0.583814   \n",
       "1     2020-08-12 14:30:15  16.079 sec              5.0       0.504835   \n",
       "2     2020-08-12 14:30:15  16.242 sec             10.0       0.463384   \n",
       "3     2020-08-12 14:30:15  16.400 sec             15.0       0.436223   \n",
       "4     2020-08-12 14:30:15  16.557 sec             20.0       0.418665   \n",
       "5     2020-08-12 14:30:15  16.706 sec             25.0       0.406488   \n",
       "6     2020-08-12 14:30:16  16.854 sec             30.0       0.397875   \n",
       "7     2020-08-12 14:30:16  17.006 sec             35.0       0.391741   \n",
       "8     2020-08-12 14:30:16  17.158 sec             40.0       0.386023   \n",
       "9     2020-08-12 14:30:16  17.314 sec             45.0       0.381194   \n",
       "10    2020-08-12 14:30:16  17.472 sec             50.0       0.376532   \n",
       "11    2020-08-12 14:30:16  17.598 sec             55.0       0.373529   \n",
       "12    2020-08-12 14:30:16  17.722 sec             60.0       0.370934   \n",
       "13    2020-08-12 14:30:17  17.828 sec             64.0       0.368727   \n",
       "\n",
       "    training_mae  training_deviance  \n",
       "0       0.441436           0.340839  \n",
       "1       0.380336           0.254859  \n",
       "2       0.346920           0.214725  \n",
       "3       0.323910           0.190291  \n",
       "4       0.308798           0.175280  \n",
       "5       0.298305           0.165232  \n",
       "6       0.290840           0.158305  \n",
       "7       0.285448           0.153461  \n",
       "8       0.280814           0.149013  \n",
       "9       0.276746           0.145309  \n",
       "10      0.273171           0.141776  \n",
       "11      0.270779           0.139524  \n",
       "12      0.268805           0.137592  \n",
       "13      0.266979           0.135959  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>relative_importance</th>\n",
       "      <th>scaled_importance</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELLER_NAME</td>\n",
       "      <td>18106.402344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROPERTY_STATE</td>\n",
       "      <td>5545.574707</td>\n",
       "      <td>0.306277</td>\n",
       "      <td>0.143113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SERVICER_NAME</td>\n",
       "      <td>3761.724121</td>\n",
       "      <td>0.207757</td>\n",
       "      <td>0.097078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ORIGINAL_UPB</td>\n",
       "      <td>1982.089600</td>\n",
       "      <td>0.109469</td>\n",
       "      <td>0.051151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCCUPANCY_STATUS</td>\n",
       "      <td>1831.757690</td>\n",
       "      <td>0.101166</td>\n",
       "      <td>0.047272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LOAN_PURPOSE</td>\n",
       "      <td>1521.354492</td>\n",
       "      <td>0.084023</td>\n",
       "      <td>0.039261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CREDIT_SCORE</td>\n",
       "      <td>1431.580322</td>\n",
       "      <td>0.079065</td>\n",
       "      <td>0.036944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ORIGINAL_LOAN_TO_VALUE</td>\n",
       "      <td>1268.270874</td>\n",
       "      <td>0.070045</td>\n",
       "      <td>0.032730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ORIGINAL_DEBT_TO_INCOME_RATIO</td>\n",
       "      <td>862.028625</td>\n",
       "      <td>0.047609</td>\n",
       "      <td>0.022246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ORIGINAL_COMBINED_LOAN_TO_VALUE</td>\n",
       "      <td>591.995483</td>\n",
       "      <td>0.032695</td>\n",
       "      <td>0.015277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>METROPOLITAN_STATISTICAL_AREA</td>\n",
       "      <td>508.515900</td>\n",
       "      <td>0.028085</td>\n",
       "      <td>0.013123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ORIGINAL_LOAN_TERM</td>\n",
       "      <td>333.235596</td>\n",
       "      <td>0.018404</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CHANNEL</td>\n",
       "      <td>283.159058</td>\n",
       "      <td>0.015639</td>\n",
       "      <td>0.007307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FIRST_TIME_HOMEBUYER_FLAG</td>\n",
       "      <td>235.832474</td>\n",
       "      <td>0.013025</td>\n",
       "      <td>0.006086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>POSTAL_CODE</td>\n",
       "      <td>159.621490</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>0.004119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PROPERTY_TYPE</td>\n",
       "      <td>128.196991</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>0.003308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NUMBER_OF_UNITS</td>\n",
       "      <td>120.852165</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>0.003119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NUMBER_OF_BORROWERS</td>\n",
       "      <td>77.363365</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.001996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           variable  relative_importance  scaled_importance  \\\n",
       "0                       SELLER_NAME         18106.402344           1.000000   \n",
       "1                    PROPERTY_STATE          5545.574707           0.306277   \n",
       "2                     SERVICER_NAME          3761.724121           0.207757   \n",
       "3                      ORIGINAL_UPB          1982.089600           0.109469   \n",
       "4                  OCCUPANCY_STATUS          1831.757690           0.101166   \n",
       "5                      LOAN_PURPOSE          1521.354492           0.084023   \n",
       "6                      CREDIT_SCORE          1431.580322           0.079065   \n",
       "7            ORIGINAL_LOAN_TO_VALUE          1268.270874           0.070045   \n",
       "8     ORIGINAL_DEBT_TO_INCOME_RATIO           862.028625           0.047609   \n",
       "9   ORIGINAL_COMBINED_LOAN_TO_VALUE           591.995483           0.032695   \n",
       "10    METROPOLITAN_STATISTICAL_AREA           508.515900           0.028085   \n",
       "11               ORIGINAL_LOAN_TERM           333.235596           0.018404   \n",
       "12                          CHANNEL           283.159058           0.015639   \n",
       "13        FIRST_TIME_HOMEBUYER_FLAG           235.832474           0.013025   \n",
       "14                      POSTAL_CODE           159.621490           0.008816   \n",
       "15                    PROPERTY_TYPE           128.196991           0.007080   \n",
       "16                  NUMBER_OF_UNITS           120.852165           0.006675   \n",
       "17              NUMBER_OF_BORROWERS            77.363365           0.004273   \n",
       "\n",
       "    percentage  \n",
       "0     0.467267  \n",
       "1     0.143113  \n",
       "2     0.097078  \n",
       "3     0.051151  \n",
       "4     0.047272  \n",
       "5     0.039261  \n",
       "6     0.036944  \n",
       "7     0.032730  \n",
       "8     0.022246  \n",
       "9     0.015277  \n",
       "10    0.013123  \n",
       "11    0.008600  \n",
       "12    0.007307  \n",
       "13    0.006086  \n",
       "14    0.004119  \n",
       "15    0.003308  \n",
       "16    0.003119  \n",
       "17    0.001996  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model summary above, we can see some of the parameters of our model, the metrics on the training data, and also the metrics from the cross-validation, as well as a detailed cross-validation metrics summary. We can also look at scoring history. However, by looking at the RMSE and MAE in the picture above for both training and validation, we can see that the model was starting to overfit because the training error is much lower than the validation error. Lastly, we can see the variable importance table, which shows both relative_importance, as well as scaled_importance, and also the percentage. For this model, the most important variable is SELLER_NAME, meaning that for our model, knowing which bank is providing the loan is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how the leader from our AutoML performs on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.18540924178823603\n",
      "RMSE: 0.4305917344634428\n",
      "MAE: 0.3115532061819847\n",
      "RMSLE: 0.051014510155050576\n",
      "Mean Residual Deviance: 0.18540924178823603\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.model_performance(test_data=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you had retrieved a different model other than the leader, and you actually wanted to check the performance of the best model in the leaderboard, you can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.18459726887069192\n",
      "RMSE: 0.42964784285585783\n",
      "MAE: 0.3116065709311251\n",
      "RMSLE: 0.05090685183518999\n",
      "Mean Residual Deviance: 0.18459726887069192\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.leader.model_performance(test_data=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the test RMSE and MAE, 0.4289 and 0.3132 respectively, are very close to the validation RMSE and MAE, 0.4309 and 0.3127, which shows us that doing 5-fold cross-validation gives us a good estimation of the error on unseen data.\n",
    "\n",
    "Now, let's make some predictions on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">  ORIGINAL_INTEREST_RATE</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">  7.0538 </td><td style=\"text-align: right;\">                   7    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  7.34609</td><td style=\"text-align: right;\">                   7.15 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  6.8593 </td><td style=\"text-align: right;\">                   6.875</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  7.1055 </td><td style=\"text-align: right;\">                   7    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  7.17164</td><td style=\"text-align: right;\">                   6.5  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  7.04135</td><td style=\"text-align: right;\">                   6.625</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  6.85598</td><td style=\"text-align: right;\">                   6.5  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  7.23544</td><td style=\"text-align: right;\">                   7.25 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  7.06726</td><td style=\"text-align: right;\">                   6.875</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  6.95089</td><td style=\"text-align: right;\">                   6.875</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = gbm.predict(test)\n",
    "pred = pred.cbind(test['ORIGINAL_INTEREST_RATE'])\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we just combined the response column from our test frame to our predictions to see how the predictions compare to the actual value.\n",
    "\n",
    "Out of the first ten predictions, most of them are very close to the actual values, with the exception of some predictions, such as the seventh prediction, which is 6.89, compared to the actual value which is 8.75. Because the RMSE is higher than the MAE, we can deduce that we have a couple of instances similar to the one mentioned above, because the larger errors are penalized more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Shutdown the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
