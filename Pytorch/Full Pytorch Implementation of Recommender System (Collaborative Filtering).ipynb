{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Pytorch Implementation of Recommender System (Collaborative Filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will utilize Pytoch's embeddings layers to build a simple recommendation system. Our model will predict user ratings for specific movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "from pathlib import Path\n",
    "from itertools import zip_longest\n",
    "from collections import defaultdict\n",
    "from urllib.error import URLError\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F \n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(state=623):\n",
    "    gens = (np.random.seed, torch.manual_seed, torch.cuda.manual_seed)\n",
    "    for set_state in gens:\n",
    "        set_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(623)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data \n",
    "The dataset is from MoiveLens Official Website [Link](https://grouplens.org/datasets/movielens/)\n",
    "Or Directdownload repo [Link](http://files.grouplens.org/datasets/movielens/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options like \n",
    "ml-latest-small, ml-1m, ml-10m, ml-20m, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def try_download(url, download_path):\n",
    "    archive_name = url.split('/')[-1]\n",
    "    folder_name, _ = os.path.splitext(archive_name)\n",
    "    \n",
    "    try:\n",
    "        r = urlopen(url)\n",
    "    except URLError as e:\n",
    "        print('Cannot download the data. Error: %s' % s)\n",
    "        return \n",
    "\n",
    "    assert r.status == 200\n",
    "    data = r.read()\n",
    "\n",
    "    with zipfile.ZipFile(io.BytesIO(data)) as arch:\n",
    "        arch.extractall(download_path)\n",
    "        \n",
    "    print('The archive is extracted into folder: %s' % download_path)\n",
    "    \n",
    "def read_data(path):\n",
    "    files = {}\n",
    "    for filename in path.glob('*'):\n",
    "        if filename.suffix == '.csv':\n",
    "            files[filename.stem] = pd.read_csv(filename)\n",
    "        elif filename.suffix == '.dat':\n",
    "            if filename.stem == 'ratings':\n",
    "                columns = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "            else:\n",
    "                columns = ['movieId', 'title', 'genres']\n",
    "            data = pd.read_csv(filename, sep='::', names=columns, engine='python')\n",
    "            files[filename.stem] = data\n",
    "    return files['ratings'], files['movies']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = Path.home() / 'Desktop' / 'Python' / 'Python-Projects'  / 'data' / 'movielens' # Path that data will be stored\n",
    "archive_url = f'http://files.grouplens.org/datasets/movielens/ml-10m.zip'   # Data URL from Grouplens website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The archive is extracted into folder: C:\\Users\\bokhy\\Desktop\\Python\\Python-Projects\\data\\movielens\n"
     ]
    }
   ],
   "source": [
    "try_download(archive_url, download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, movies = read_data(download_path / 'ml-10M100K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838985046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>5.0</td>\n",
       "      <td>838983392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1      122     5.0  838985046\n",
       "1       1      185     5.0  838983525\n",
       "2       1      231     5.0  838983392\n",
       "3       1      292     5.0  838983421\n",
       "4       1      316     5.0  838983392"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function from 'https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(ratings, top=None):\n",
    "    if top is not None:\n",
    "        ratings.groupby('userId')['rating'].count()\n",
    "    \n",
    "    unique_users = ratings.userId.unique()\n",
    "    user_to_index = {old: new for new, old in enumerate(unique_users)}\n",
    "    new_users = ratings.userId.map(user_to_index)\n",
    "    \n",
    "    unique_movies = ratings.movieId.unique()\n",
    "    movie_to_index = {old: new for new, old in enumerate(unique_movies)}\n",
    "    new_movies = ratings.movieId.map(movie_to_index)\n",
    "    \n",
    "    n_users = unique_users.shape[0]\n",
    "    n_movies = unique_movies.shape[0]\n",
    "    \n",
    "    X = pd.DataFrame({'user_id': new_users, 'movie_id': new_movies})\n",
    "    y = ratings['rating'].astype(np.float32)\n",
    "    return (n_users, n_movies), (X, y), (user_to_index, movie_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 69878 users, 10677 movies\n",
      "Dataset shape: (10000054, 2)\n",
      "Target shape: (10000054,)\n"
     ]
    }
   ],
   "source": [
    "(n, m), (X, y), _ = create_dataset(ratings)\n",
    "print(f'Embeddings: {n} users, {m} movies')\n",
    "print(f'Dataset shape: {X.shape}')\n",
    "print(f'Target shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset one batch after another:\n",
    "\n",
    "class ReviewsIterator:\n",
    "    \n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        \n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "            \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] // batch_size))\n",
    "        self._current = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        if self._current >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self._current\n",
    "        self._current += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k*bs:(k + 1)*bs], self.y[k*bs:(k + 1)*bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into smaller chunks during training/validation process:\n",
    "def batches(X, y, bs=32, shuffle=True):\n",
    "    for xb, yb in ReviewsIterator(X, y, bs, shuffle):\n",
    "        xb = torch.LongTensor(xb)\n",
    "        yb = torch.FloatTensor(yb)\n",
    "        yield xb, yb.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27100,   951],\n",
      "        [28508,   620],\n",
      "        [38665,    93],\n",
      "        [22287,  5253]])\n",
      "tensor([[2.],\n",
      "        [4.],\n",
      "        [4.],\n",
      "        [4.]])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in batches(X, y, bs=4):\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings\n",
    "It allows to create a network of arbirary depth, with or without dropouts. Also, the forward method accepts an additional minmax argument which is expected to be a tuple with minimum and maximum values of ratings from the dataset to normalize the predicted value into specific range.\n",
    "\n",
    "Note that to create a group of hidden layers we use a generator function gen_layers that yields linear and dropout layers depending on values from hidden and dropouts arrays. Also note that we use the nn.Sequence class to group hidden layers into a single module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates a dense network with embedding layers.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        n_users:            \n",
    "            Number of unique users in the dataset.\n",
    "\n",
    "        n_movies: \n",
    "            Number of unique movies in the dataset.\n",
    "\n",
    "        n_factors: \n",
    "            Number of columns in the embeddings matrix.\n",
    "\n",
    "        embedding_dropout: \n",
    "            Dropout rate to apply right after embeddings layer.\n",
    "\n",
    "        hidden:\n",
    "            A single integer or a list of integers defining the number of \n",
    "            units in hidden layer(s).\n",
    "\n",
    "        dropouts: \n",
    "            A single integer or a list of integers defining the dropout \n",
    "            layers rates applyied right after each of hidden layers.\n",
    "            \n",
    "    \"\"\"\n",
    "    def __init__(self, n_users, n_movies,\n",
    "                 n_factors=50, embedding_dropout=0.02, \n",
    "                 hidden=10, dropouts=0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        hidden = get_list(hidden)\n",
    "        dropouts = get_list(dropouts)\n",
    "        n_last = hidden[-1]\n",
    "        \n",
    "        def gen_layers(n_in):\n",
    "            \"\"\"\n",
    "            A generator that yields a sequence of hidden layers and \n",
    "            their activations/dropouts.\n",
    "            \n",
    "            Note that the function captures `hidden` and `dropouts` \n",
    "            values from the outer scope.\n",
    "            \"\"\"\n",
    "            nonlocal hidden, dropouts\n",
    "            assert len(dropouts) <= len(hidden)\n",
    "            \n",
    "            for n_out, rate in zip_longest(hidden, dropouts):\n",
    "                yield nn.Linear(n_in, n_out)\n",
    "                yield nn.ReLU()\n",
    "                if rate is not None and rate > 0.:\n",
    "                    yield nn.Dropout(rate)\n",
    "                n_in = n_out\n",
    "            \n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 2)))\n",
    "        self.fc = nn.Linear(n_last, 1)\n",
    "        self._init()\n",
    "        \n",
    "    def forward(self, users, movies, minmax=None):\n",
    "        features = torch.cat([self.u(users), self.m(movies)], dim=1)\n",
    "        x = self.drop(features)\n",
    "        x = self.hidden(x)\n",
    "        out = torch.sigmoid(self.fc(x))\n",
    "        if minmax is not None:\n",
    "            min_rating, max_rating = minmax\n",
    "            out = out*(max_rating - min_rating + 1) + min_rating - 0.5\n",
    "        return out\n",
    "    \n",
    "    def _init(self):\n",
    "        \"\"\"\n",
    "        Setup embeddings and hidden layers with reasonable initial values.\n",
    "        \"\"\"\n",
    "        \n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "                \n",
    "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.m.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.fc)\n",
    "    \n",
    "    \n",
    "def get_list(n):\n",
    "    if isinstance(n, (int, float)):\n",
    "        return [n]\n",
    "    elif hasattr(n, '__iter__'):\n",
    "        return list(n)\n",
    "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So for example, if we want to create a network with a single hidden layer and dropout, we can use the following code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EmbeddingNet(n, m, n_factors=150, hidden=100, dropouts=0.5)                     # for simple model\n",
    "# EmbeddingNet(n, m, n_factors=150, hidden=[100, 200, 300], dropouts=[0.25, 0.5]) # or you can pass list of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclical Learning Rate (CLR)\n",
    "##### From 'https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb'\n",
    "One of the fastai library features is the cyclical learning rate scheduler. We can implement something similar inheriting the _LRScheduler class from the torch library. Following the original paper's pseudocode, this CLR Keras callback implementation, and making a couple of adjustments to support cosine annealing with restarts, let's create our own CLR scheduler.\n",
    "\n",
    "The implementation of this idea is quite simple. The base PyTorch scheduler class has the get_lr() method that is invoked each time when we call the step() method. The method should return a list of learning rates depending on the current training epoch. In our case, we have the same learning rate for all of the layers, and therefore, we return a list with a single value.\n",
    "\n",
    "The next cell defines a CyclicLR class that expectes a single callback function. This function should accept the current training epoch and the base value of learning rate, and return a new learning rate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we only need to define appropriate scheduling functions. We're createing a couple of functions that accept scheduling parameters and return a new function with the appropriate signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangular(step_size, max_lr, method='triangular', gamma=0.99):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        period = 2 * step_size\n",
    "        cycle = math.floor(1 + epoch/period)\n",
    "        x = abs(epoch/step_size - 2*cycle + 1)\n",
    "        delta = (max_lr - base_lr)*max(0, (1 - x))\n",
    "\n",
    "        if method == 'triangular':\n",
    "            pass  # we've already done\n",
    "        elif method == 'triangular2':\n",
    "            delta /= float(2 ** (cycle - 1))\n",
    "        elif method == 'exp_range':\n",
    "            delta *= (gamma**epoch)\n",
    "        else:\n",
    "            raise ValueError('unexpected method: %s' % method)\n",
    "            \n",
    "        return base_lr + delta\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + math.cos(math.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr(schedule):\n",
    "    ts = list(range(1000))\n",
    "    y = [schedule(t, 0.001) for t in ts]\n",
    "    plt.plot(ts, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plots visualizing learning rates changes depending on the number of epoch:\n",
    "plot_lr(cosine(t_max=500, eta_min=0.0005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=623)\n",
    "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid)}\n",
    "dataset_sizes = {'train': len(X_train), 'val': len(X_valid)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Check Target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 5.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax = ratings.rating.min(), ratings.rating.max()\n",
    "minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) Define a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = EmbeddingNet(\n",
    "    n_users=n, \n",
    "    n_movies=m, \n",
    "    n_factors=150, \n",
    "    hidden=[500, 500, 500], \n",
    "    embedding_dropout=0.05, \n",
    "    dropouts=[0.5, 0.5, 0.25]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (4) Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is preparing and running the training loop with cyclical learning rate, validation and early stopping. We use Adam optimizer with cosine-annealing learnign rate. The rate is decreased on each batch during 2 epochs, and then is reset to the original value.\n",
    "\n",
    "Note that our loop has two phases. One of them is called train. During this phase, we update our network's weights and change the learning rate. The another one is called val and is used to check the model's performence. When the loss value decreases, we save model parameters to restore them later. If there is no improvements after 10 sequential training epochs, we exit from the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter setting\n",
    "lr = 0.01\n",
    "wd = 0.01\n",
    "bs = 16\n",
    "n_epochs = 10\n",
    "patience = 10\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "\n",
    "from adamp import AdamP\n",
    "# https://github.com/clovaai/AdamP\n",
    "# Other than learning rate and weight_decay, two more parameters can be passed (default is usually ok)\n",
    "# delta : threhold that determines whether a set of parameters is scale invariant or not (default: 0.1)\n",
    "# wd_ratio : relative weight decay applied on scale-invariant parameters compared to that applied on scale-variant parameters (default: 0.1)\n",
    "# optimizer = AdamP(net.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "# Regular Adam Optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingNet(\n",
       "  (u): Embedding(69878, 150)\n",
       "  (m): Embedding(10677, 150)\n",
       "  (drop): Dropout(p=0.05, inplace=False)\n",
       "  (hidden): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "    \n",
    "    for phase in ('train', 'val'):\n",
    "        training = phase == 'train'\n",
    "        running_loss = 0.0\n",
    "        n_batches = 0\n",
    "        \n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = net(x_batch[:, 1], x_batch[:, 0], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                \n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    lr_history.extend(scheduler.get_lr())\n",
    "                    \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        \n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(net.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "                \n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the training process was terminated after 16 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(history).drop(columns='total').plot(x='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that learning rate is updated in accordance with cosine annealing schedule.\n",
    "_ = plt.plot(lr_history[:2*iterations_per_epoch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's restore the best weights saved during training, and apply the model to the validation subset of the data to see the final model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groud_truth, predictions = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in batches(*datasets['val'], shuffle=False, bs=bs):\n",
    "        x_batch, y_batch = [b.to(device) for b in batch]\n",
    "        outputs = net(x_batch[:, 1], x_batch[:, 0], minmax)\n",
    "        groud_truth.extend(y_batch.tolist())\n",
    "        predictions.extend(outputs.tolist())\n",
    "\n",
    "groud_truth = np.asarray(groud_truth).ravel()\n",
    "predictions = np.asarray(predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss = np.sqrt(np.mean((predictions - groud_truth)**2))\n",
    "print(f'Final RMSE: {final_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best.weights', 'wb') as file:\n",
    "    pickle.dump(best_weights, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we apply the Principal Components Analysis (PCA) to reduce the dimentionality of embeddings and show some of them with bar plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading previously saved weights using Pytorch's 'load_state_dict' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best.weights', 'rb') as file:\n",
    "    best_weights = pickle.load(file)\n",
    "net.load_state_dict(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the mappings between original users's and movies's IDs, and new contiguous values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, (user_id_map, movie_id_map) = create_dataset(ratings)\n",
    "embed_to_original = {v: k for k, v in movie_id_map.items()}\n",
    "popular_movies = ratings.groupby('movieId').movieId.count().sort_values(ascending=False).values[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the dimensionality of movie embeddings vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = to_numpy(net.m.weight.data)\n",
    "pca = PCA(n_components=5)\n",
    "components = pca.fit(embed[popular_movies].T).components_\n",
    "components.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a joined data frame with projected embeddings and movies they represent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df = pd.DataFrame(components.T, columns=[f'fc{i}' for i in range(pca.n_components_)])\n",
    "movie_ids = [embed_to_original[idx] for idx in components_df.index]\n",
    "meta = movies.set_index('movieId')\n",
    "components_df['movie_id'] = movie_ids\n",
    "components_df['title'] = meta.loc[movie_ids].title.values\n",
    "components_df['genres'] = meta.loc[movie_ids].genres.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_components(components, component, ascending=False):\n",
    "    fig, ax = plt.subplots(figsize=(18, 12))\n",
    "    \n",
    "    subset = components.sort_values(by=component, ascending=ascending).iloc[:12]\n",
    "    columns = components_df.columns\n",
    "    features = columns[columns.str.startswith('fc')].tolist()\n",
    "    \n",
    "    fc = subset[features]\n",
    "    titles = ['\\n'.join(wrap(t, width=10)) for t in subset.title]\n",
    "    genres = subset.genres.str.replace('|', '\\n')\n",
    "    labels = [f'{t}\\n\\n{g}' for t, g in zip(titles, genres)]\n",
    "    \n",
    "    fc.plot(ax=ax, kind='bar')\n",
    "    y_ticks = [f'{t:2.2f}' for t in ax.get_yticks()]\n",
    "    ax.set_xticklabels(labels, rotation=0, fontsize=14)\n",
    "    ax.set_yticklabels(y_ticks, fontsize=14)\n",
    "    ax.legend(loc='best', fontsize=14)\n",
    "    \n",
    "    plot_title = f\"Movies with {['highest', 'lowest'][ascending]} '{component}' component values\" \n",
    "    ax.set_title(plot_title, fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the visualizations below, we could make a guess that the red component mostly reflects the rate of \"seriousness\" in the movie. Comedies, animations and adventures mostly have the negative values of this feature while more \"dramatical\" movies have high levels of this component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_components(components_df, 'fc0', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_components(components_df, 'fc0', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference\n",
    ">https://medium.com/@iliazaitsev/how-to-implement-a-recommendation-system-with-deep-learning-and-pytorch-2d40476590f9\n",
    ">https://github.com/devforfu/pytorch_playground/blob/master/movielens.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
